{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 BERT Email Classifier Training Notebook\n",
    "\n",
    "This notebook trains a BERT model to classify emails into different categories using our synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get everything running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your terminal "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1) Install uv (one time)\n",
    "# macOS/Linux:\n",
    "#curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# Windows (PowerShell):\n",
    "#irm https://astral.sh/uv/install.ps1 | iex\n",
    "\n",
    "# 2) Project folder\n",
    "mkdir car-email-classifier && cd car-email-classifier\n",
    "\n",
    "# 3) Create env + install deps (very fast)\n",
    "uv venv\n",
    "uv pip install -U pip\n",
    "uv pip install jupyterlab ipykernel pandas scikit-learn matplotlib tqdm \\\n",
    "               transformers accelerate huggingface_hub \\\n",
    "               torch \\\n",
    "               google-genai ipywidgets\n",
    "# Optional extras:\n",
    "# uv pip install bitsandbytes llama-cpp-python gpt4all\n",
    "\n",
    "# 4) Make the ipykernel visible in Jupyter\n",
    "python -m ipykernel install --user --name car-email-classifier\n",
    "\n",
    "# 5) Launch\n",
    "#jupyter lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.7.1\n",
      "Transformers: 4.55.0\n",
      "Pandas: 2.3.1\n",
      "CUDA: False\n",
      "MPS: True\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, sklearn, pandas as pd\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(\"MPS:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Install Required Packages\n",
    "\n",
    "Run this cell first to install all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (4.55.0)\n",
      "Requirement already satisfied: torch in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: datasets in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (1.9.0)\n",
      "Requirement already satisfied: filelock in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (2025.7.31)\n",
      "Requirement already satisfied: requests in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: psutil in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers and datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Disable wandb logging\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "print('✅ All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 BERT Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be run at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Setting up BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer loaded: distilbert-base-uncased\n",
      "✅ Model loaded with 6 output classes\n",
      "✅ Model moved to mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "print('🧠 Setting up BERT model...')\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(f'Tokenizer loaded: {model_name}')\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels\n",
    ")\n",
    "print(f'Model loaded with {num_labels} output classes')\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f'Model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE UNTIL WORKSHOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎮 GPU Detection & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS GPU (Metal Performance Shaders)\n",
      "PyTorch version: 2.7.1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Detect and set up GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using CUDA GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using Apple MPS GPU (Metal Performance Shaders)')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU found — using CPU (training will be slower)')\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to get the dataset and be able to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded! Shape: (948, 4)\n",
      "Total emails: 948\n",
      "Categories: 6\n",
      "\n",
      "Category distribution:\n",
      "Label\n",
      "CarBreakdown     160\n",
      "CarTheft         160\n",
      "CarRenewal       160\n",
      "CarCrash         160\n",
      "CarWindshield    160\n",
      "Other            148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the complete dataset\n",
    "print('Loading dataset...')\n",
    "df = pd.read_csv('../data/complete_dataset_augmented.csv')\n",
    "print(f'Dataset loaded! Shape: {df.shape}')\n",
    "print(f'Total emails: {len(df)}')\n",
    "print(f'Categories: {df[\"Label\"].nunique()}')\n",
    "print('\\nCategory distribution:')\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Data preprocessing...\n",
      "Combined text created. Sample length: 324 chars\n",
      "Labels encoded. Classes: ['CarBreakdown' 'CarCrash' 'CarRenewal' 'CarTheft' 'CarWindshield' 'Other']\n",
      "Data split complete:\n",
      "   Training: {len(X_train)} samples\n",
      "   Testing: {len(X_test)} samples\n",
      "   Classes: {len(label_encoder.classes_)}\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "print('🔧 Data preprocessing...')\n",
    "\n",
    "# Combine subject and message\n",
    "df['text'] = df['Subject'] + ' ' + df['Message']\n",
    "print(f'Combined text created. Sample length: {len(df[\"text\"].iloc[0])} chars')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['Label'])\n",
    "print(f'Labels encoded. Classes: {label_encoder.classes_}')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label_encoded'], \n",
    "    test_size=0.2, random_state=42, stratify=df['label_encoded']\n",
    ")\n",
    "\n",
    "print('Data split complete:')\n",
    "print('   Training: {len(X_train)} samples')\n",
    "print('   Testing: {len(X_test)} samples')\n",
    "print('   Classes: {len(label_encoder.classes_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Tokenizing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63307f2f56c3465384741672b1dbf14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf1c3ef84c248a6832d3266fdf569c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data tokenized successfully!\n",
      "   Training samples: 758\n",
      "   Test samples: 190\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "print('📝 Tokenizing data...')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Create datasets for HuggingFace\n",
    "train_ds = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_ds = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "# Convert to HuggingFace Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_ds)\n",
    "test_dataset = Dataset.from_pandas(test_ds)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print('Data tokenized successfully!')\n",
    "print(f'   Training samples: {len(train_dataset)}')\n",
    "print(f'   Test samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Using batch size: 8\n",
      "✅ Training configuration set!\n"
     ]
    }
   ],
   "source": [
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# Set batch size based on device\n",
    "batch_size = 16 if torch.cuda.is_available() else 8\n",
    "print(f'📦 Using batch size: {batch_size}')\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-email-classifier\",\n",
    "    do_train=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    # GPU optimizations\n",
    "    dataloader_pin_memory=True if torch.cuda.is_available() else False,\n",
    "    fp16=torch.cuda.is_available(), # Use mixed precision on GPU\n",
    "    gradient_accumulation_steps=2 if torch.cuda.is_available() else 1\n",
    ")\n",
    "\n",
    "print('✅ Training configuration set!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS GPU (Metal Performance Shaders)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [475/475 08:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Detect and set up GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using CUDA GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using Apple MPS GPU (Metal Performance Shaders)')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU found — using CPU (training will be slower)')\n",
    "# Train the model\n",
    "trainer.train()\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Evaluation Results:\n",
      "   eval_loss: 0.0065\n",
      "   eval_accuracy: 1.0000\n",
      "   eval_f1: 1.0000\n",
      "   eval_runtime: 6.6009\n",
      "   eval_samples_per_second: 28.7840\n",
      "   eval_steps_per_second: 3.6360\n",
      "   epoch: 5.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('📊 Evaluating model...')\n",
    "results = trainer.evaluate()\n",
    "print('\\n📈 Evaluation Results:')\n",
    "for key, value in results.items():\n",
    "    print(f'   {key}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Making predictions...\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " CarBreakdown       1.00      1.00      1.00        32\n",
      "     CarCrash       1.00      1.00      1.00        32\n",
      "   CarRenewal       1.00      1.00      1.00        32\n",
      "     CarTheft       1.00      1.00      1.00        32\n",
      "CarWindshield       1.00      1.00      1.00        32\n",
      "        Other       1.00      1.00      1.00        30\n",
      "\n",
      "     accuracy                           1.00       190\n",
      "    macro avg       1.00      1.00      1.00       190\n",
      " weighted avg       1.00      1.00      1.00       190\n",
      "\n",
      "\n",
      "🔍 Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5sAAAMWCAYAAAB/RZIWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAmJJJREFUeJzs3Qd8k9X3+PHTAm3Ze6rsvYdsZCjIUGQLiICCDBnKhopsEBUBZSMoIIIoMkWEr6DgYCN7T1H23pv8X+f6T35Jw2jJU5Kn/by/r3xpRpPbXp8m5znnnhvkcDgcAgAAAACAhYKtfDIAAAAAABTBJgAAAADAcgSbAAAAAADLEWwCAAAAACxHsAkAAAAAsBzBJgAAAADAcgSbAAAAAADLEWwCAAAAACxHsAkAAAAAsBzBJgAgxtq3b5+8+OKLkjRpUgkKCpL58+db+vyHDx82zzt16lRLn9fOKlasaC4AABBsAgCi1YEDB6RNmzaSNWtWCQsLkyRJkkjZsmXls88+k+vXr0frazdv3ly2bdsmQ4YMkenTp8uzzz4rMcUbb7xhAl39fd7v96iBtt6vl08++STKz3/s2DHp37+/bN682aIRAwBim7j+HgAAIOb68ccfpUGDBhIaGirNmjWT/Pnzy61bt+SPP/6Q7t27y44dO+Tzzz+PltfWAGz16tXSu3dv6dChQ7S8RqZMmczrxIsXT/whbty4cu3aNfnhhx/k1Vdf9bhvxowZJri/cePGYz23BpsDBgyQzJkzS+HChSP9ff/73/8e6/UAADEPwSYAIFocOnRIGjVqZAKyX375RdKnT++6r3379rJ//34TjEaX06dPm3+TJUsWba+hWUMN6PxFg3jNEn/zzTdewebMmTPlpZdekjlz5jyRsWjQmyBBAgkJCXkirwcACHyU0QIAosXHH38sV65ckS+++MIj0HTKnj27vPvuu67rd+7ckUGDBkm2bNlMEKUZtffee09u3rzp8X16+8svv2yyoyVKlDDBnpbofvXVV67HaPmnBrlKM6gaFOr3OctPnV+70+/Rx7n7+eefpVy5ciZgTZQokeTKlcuM6VFrNjW4fu655yRhwoTme2vVqiW7du267+tp0K1j0sfp2tI333zTBG6R9dprr8lPP/0kFy5ccN22fv16U0ar90V07tw56datmxQoUMD8TFqGW716ddmyZYvrMStWrJDixYubr3U8znJc58+pazI1S71x40YpX768CTKdv5eIaza1lFnnKOLPX7VqVUmePLnJoAIAYiaCTQBAtNDSTg0Cy5QpE6nHv/XWW9K3b18pWrSojBw5UipUqCBDhw412dGINECrX7++VKlSRYYPH26CFg3YtCxX1a1b1zyHaty4sVmv+emnn0Zp/PpcGtRqsDtw4EDzOq+88or8+eefD/2+ZcuWmUDq1KlTJqDs0qWLrFq1ymQgNTiNSDOSly9fNj+rfq0BnZavRpb+rBoIzp071yOrmTt3bvO7jOjgwYOmUZL+bCNGjDDBuK5r1d+3M/DLkyeP+ZlV69atze9PLxpYOp09e9YEqVpiq7/bSpUq3Xd8ujY3derUJui8e/euuW3ixImm3Hb06NGSIUOGSP+sAACbcQAAYLGLFy869C2mVq1akXr85s2bzePfeustj9u7detmbv/ll19ct2XKlMnc9ttvv7luO3XqlCM0NNTRtWtX122HDh0yjxs2bJjHczZv3tw8R0T9+vUzj3caOXKkuX769OkHjtv5GlOmTHHdVrhwYUeaNGkcZ8+edd22ZcsWR3BwsKNZs2Zer9eiRQuP56xTp44jZcqUD3xN958jYcKE5uv69es7XnjhBfP13bt3HenSpXMMGDDgvr+DGzdumMdE/Dn09zdw4EDXbevXr/f62ZwqVKhg7pswYcJ979OLu6VLl5rHDx482HHw4EFHokSJHLVr137kzwgAsDcymwAAy126dMn8mzhx4kg9fvHixeZfzQK669q1q/k34trOvHnzmjJVJ82caYmrZu2s4lzruWDBArl3716kvuf48eOme6tmWVOkSOG6vWDBgiYL6/w53bVt29bjuv5cmjV0/g4jQ8tltfT1xIkTpoRX/71fCa3SEuXg4P/e/jXTqK/lLBH+66+/Iv2a+jxaYhsZuv2MdiTWbKlmYrWsVrObAICYjWATAGA5XQeotDw0Mv7++28TAOk6Tnfp0qUzQZ/e7y5jxoxez6GltOfPnxerNGzY0JS+anlv2rRpTTnvd99999DA0zlODdwi0tLUM2fOyNWrVx/6s+jPoaLys9SoUcME9t9++63pQqvrLSP+Lp10/FpinCNHDhMwpkqVygTrW7dulYsXL0b6NZ966qkoNQPS7Vc0ANdgfNSoUZImTZpIfy8AwJ4INgEA0RJs6lq87du3R+n7IjboeZA4ceLc93aHw/HYr+FcT+gUP358+e2338wazKZNm5pgTANQzVBGfKwvfPlZnDRo1IzhtGnTZN68eQ/MaqoPPvjAZJB1/eXXX38tS5cuNY2Q8uXLF+kMrvP3ExWbNm0y61iVrhEFAMR8BJsAgGihDWgOHDhg9rp8FO0cq4GOdlB1d/LkSdNl1dlZ1gqaOXTv3OoUMXuqNNv6wgsvmEY6O3fulCFDhpgy1V9//fWBP4fas2eP1327d+82WUTtUBsdNMDUgE6zyfdrquT0/fffm2Y+2iVYH6clrpUrV/b6nUQ28I8MzeZqya2WP2vDIe1UrB1zAQAxG8EmACBa9OjRwwRWWoaqQWNEGohqp1JnGaiK2DFWgzyl+0VaRbdW0XJRzVS6r7XUjGDELUIi0s6rKuJ2LE66xYs+RjOM7sGbZni1+6rz54wOGkDq1jFjxowx5ccPy6RGzJrOnj1bjh496nGbMyi+X2AeVT179pQjR46Y34vOqW49o91pH/R7BADEDHH9PQAAQMykQZ1uwaGlp7pesVmzZmZvxlu3bpmtQDTA0UY6qlChQib4+Pzzz01wo9twrFu3zgQntWvXfuC2Go9Ds3ka/NSpU0feeecds6fl+PHjJWfOnB4NcrSZjZbRaqCrGUstAR03bpw8/fTTZu/NBxk2bJjZEqR06dLSsmVLuX79utniQ/fQ1K1QootmYd9///1IZZz1Z9NMo25LoyWtus5Tt6mJOH+6XnbChAlmPagGnyVLlpQsWbJEaVyaCdbfW79+/VxbsUyZMsXsxdmnTx+T5QQAxExkNgEA0Ub3pdQMou6JqV1d27dvL7169TL7Teq+ldooxmny5Mlmf0ktr+zUqZMJUsLDw2XWrFmWjillypQmi5kgQQKTfdWAVve4rFmzptfYtXnPl19+acY9duxYs85Rx6WB44NoSeqSJUvM6+i+odoYp1SpUmZ/zqgGatHhvffeM11+da3mu+++awJs7fb7zDPPeDwuXrx45nejmVDtmKv7la5cuTJKr6UlvS1atJAiRYpI7969PTru6mvrfwNr1qyx7GcDAASWIN3/xN+DAAAAAADELGQ2AQAAAACWI9gEAAAAAFiOYBMAAAAAYDmCTQAAAACA5Qg2AQAAAACWI9gEAAAAAFiOYBMAAAAAYLm41j8lYrr4RTr4ewjwwfn1Y/w9BAAAgEgLs0nE4u/PyNc3Bd5nPDKbAAAAAADLEWwCAAAAACxnk6Q0AAAAAASwIPJ4EfEbAQAAAABYjswmAAAAAPgqKMjfIwg4ZDYBAAAAAJYj2AQAAAAAWI4yWgAAAADwFQ2CvPAbAQAAAABYjswmAAAAAPiKBkFeyGwCAAAAACxHsAkAAAAAsBxltAAAAADgKxoEeeE3AgAAAACwHJlNAAAAAPAVDYK8kNkEAAAAAFiOYBMAAAAAYDnKaAEAAADAVzQI8sJvBAAAAABgOTKbAAAAAOArGgR5IbMJAAAAALAcwSYAAAAAwHKU0QIAAACAr2gQ5IXfCAAAAADAcmQ2AQAAAMBXNAjyQmYTAAAAAGA5gk0AAAAAgOUoowUAAAAAX9EgyAu/EQAAAACA5chsAgAAAICvaBDkhcwmAAAAAMByBJsAAAAAAMtRRgsAAAAAvqJBkBd+IwAAAAAAy5HZBAAAAABfkdn0wm8EAAAAAGKR8ePHS8GCBSVJkiTmUrp0afnpp59c99+4cUPat28vKVOmlESJEkm9evXk5MmTUX4dgk0AAAAAiEWefvpp+fDDD2Xjxo2yYcMGef7556VWrVqyY8cOc3/nzp3lhx9+kNmzZ8vKlSvl2LFjUrdu3Si/TpDD4XBEw/gRg8Uv0sHfQ4APzq8f4+8hAAAARFqYTRb+xa80yK+vf/3XPj59f4oUKWTYsGFSv359SZ06tcycOdN8rXbv3i158uSR1atXS6lSpSL9nGQ2AQAAAMDmbt68KZcuXfK46G2PcvfuXZk1a5ZcvXrVlNNqtvP27dtSuXJl12Ny584tGTNmNMFmVBBsAgAAAIAVDYL8eBk6dKgkTZrU46K3Pci2bdvMeszQ0FBp27atzJs3T/LmzSsnTpyQkJAQSZYsmcfj06ZNa+6LCpskpQEAAAAADxIeHi5dunTxuE0DyQfJlSuXbN68WS5evCjff/+9NG/e3KzPtBLBJgAAAADYXGho6EODy4g0e5k9e3bzdbFixWT9+vXy2WefScOGDeXWrVty4cIFj+ymdqNNly5dlMZEGS0AAAAA+CooyL8XH927d8+s8dTAM168eLJ8+XLXfXv27JEjR46YNZ1RQWYTAAAAAGJZyW316tVN05/Lly+bzrMrVqyQpUuXmrWeLVu2NCW52qFW9+Hs2LGjCTSj0olWEWwCAAAAgK+0UY9NnDp1Spo1aybHjx83wWXBggVNoFmlShVz/8iRIyU4OFjq1atnsp1Vq1aVcePGRfl12GczmkydOlU6depkap0jS88mVKpUSc6fP+/V/SmQsM+mvbHPJgAAsBPb7LNZ+UO/vv71Zb0k0Pg9/Nb2uZqWzZo1q1nQ+swzz0jNmjU9aoQfR//+/SUoKMh10Yj9ueees7zDEuypVYNysu7bcDn5+zBzWTGtq7xYNq+5L3mSBDKiZwPZMq+PnFs9QvYuHijDe9SXJInC/D1sPMKsmTOkepXnpXiRAtKkUQPZtnWrv4eESGLu7I35szfmz96YPwQyvwabhw8fNgtQf/nlFxk2bJjZ62XJkiUmu9e+ffvHek7dlFQXt6p8+fKZ1LBedAPSHDlyyMsvv2za+z6IbmCKmO/oyQvSZ/QCKdPkYynbZJisWLdXZo9sLXmyppP0qZOaS/jIeVKswQfSqt/XUqVMXpnQr4m/h42HWPLTYvnk46HSpl17mTV7nuTKlVvebtNSzp496++h4RGYO3tj/uyN+bM35i/A2LxBUIwLNtu1a2eyjuvWrTP1wDlz5jQBoi5GXbNmjXnMiBEjpECBApIwYUKT9dTvuXLlike5qpacLly40GxCqtlR7ZSk4saNa9rz6kXvGzhwoPnevXv3ur5fX3/8+PHyyiuvmNcYMmSIuX3BggVStGhRCQsLM1nXAQMGyJ07d1zf96hxRXT69Gl59tlnpU6dOqbuWS1evNj8zPHjxzcBtgbfEc2ZM8f8TvTnypw5swwfPtx135gxYyR//vyu6/Pnzzc/z4QJE1y3Va5cWd5//31Xtrdw4cIyffp081ya7W3UqJFZFBzbLP5tuyz9Y6ccOHJa9h85Jf3H/iBXrt2UEgWzyM4Dx6Vxt8nmMYf+PSMr1++V/mN+kBrl80ucOH4vBsADTJ82RerWf1Vq16kn2bJnl/f7DTDH7/y5c/w9NDwCc2dvzJ+9MX/2xvwh0Pntk/O5c+dMFlMzmBqwReRcs6gLU0eNGiU7duyQadOmmSxojx49PB577do1+eijj2Ty5MnmcWnSpPF6Pg3wpkyZYp5XNzB1p0GYBoGaWW3RooX8/vvvZsHsu+++Kzt37pSJEyeaoNYZiEZ2XE7//POPKeHVwFA3TNXAUW+rW7euKRnWzVTfeust6dXLs85648aN8uqrr5qAUMem4+zTp48Zi6pQoYIZnwaySkuEU6VKZdZ+OrO0mtGtWLGi6zkPHDhggtJFixaZi37Phx/6t77c34KDg6RB1WKSMH6IrN166L6PSZI4TC5dvSF37/6XNUdguX3rluzauUNKlS7jcYyWKlVGtm7Z5Nex4eGYO3tj/uyN+bM35i9AGwT58xKA/Lbcdv/+/aK9iXLnzv3Qx2mTHSfNxg0ePFjatm3r0Q1Jgyq9XqhQIY/v1QAtUaJEroA0ceLE8u2335r2ve5ee+01efPNN13XNeDUwK958+bmumY2Bw0aZILJfv36RXpczj1ptKuTBrOffvqpyTwqzaZmy5bNlanUAFjHq0Gze/b0hRdeMAGm0iyoBpdacvzGG2+Y4FXbEWvAWL9+fRNkdu3a1WzGqjRjrL+bMmX+74+QlhhrsKq/C9W0aVOzPtY9kI4t8mXPYNZqhoXElSvXb0rDrpNk98ETXo9LmSyhhLeqLl/OWeWXceLRzl84b0roU6ZM6XG7Xj906KDfxoVHY+7sjfmzN+bP3pg/2IHfQuDINsFdtmyZCbieeuopEyBpcKR16Bo8OoWEhJh2vRFpAKdZQ71olvDtt9+WBg0ayIYNGzwep+Wt7rZs2WJKbjVQdV5atWpl1n46Xzcy47p+/brJaGoGUwNAZ6Cpdu3aJSVLlvR43YibpOpjypYt63GbXt+3b5/546LPV758eRNkatdbDUS1nFezuLt37zZBaPHixSVBggQegbEz0FTp06c3rY8fRJ/r0qVLHhfHvbsSE+w9fFJKNhoq5Zt9IpNm/yGTBjaV3FnTeTwmccIwmTfqbdl18LgMnvij38YKAAAA2I3fgk1t1qPBkgZFD6JrGLWhjwaSunZRA8axY8ea+27duuV6nK55dA/k3IPQ7Nmzm0uRIkVMuagGh5phdBexjFfXXuoaTWegqhfNOmqQp3XwkR2XlsvqmkktVz169KhEBy2R1WBTS3/1Z9SsrTMA1WBTS23dxYsXz+O6/t6cDZXuZ+jQoWZtp/vlzsmNEhPcvnNXDv5zRjbt+kf6jl4o2/YelfaN/6/kOFGCUFk4tp1cvnZDGnaZJHfuUEIbqJInSy5x4sTxaoig17W0HIGLubM35s/emD97Y/4CEA2CAifY1PJP3RxUg7SrV6963a+ZOg3iNBDSUtNSpUqZMtJjx4759Lp6UGrG8WG0MZCWvzoDVfeL1sJHdlz6WG3Gox13tQGQ+2Py5MljylzdOZsiuT/mzz//9LhNr+vr6c/hvm5z9uzZrrWZ+q9mXvWx7us1H0d4eLjp3ut+iZu2mMREwUFBEhoS15XRXDS+g9y6fVfqd5ooN2/9X3MoBJ54ISGSJ28+Wbtmtes2PUbXrl0tBQsV8evY8HDMnb0xf/bG/Nkb8wc78OtKUg00tRy0RIkSJkOomUMtHdXGO1pSqsGdrjkcPXq0HDx40ARu7p1WH0W7x+o+nnrR59Z1lRqY1apV66Hf17dvX/nqq69MdlMbAOmYZs2a5erqGpVxaVA4Y8YMs570+eefN2NRur5Tx9S9e3cT2M6cOdPV+MdJ11/qekpdL6oddLURkXag7datm+sxml1Nnjy5+X73YFObAGkJbMQy3KjS7KxmS90vQcH/Bbp2NrDjK1K2aDbJmD6FWbup18s/m0NmLd7wX6A5rr0kCAuRtgNmSJKEYZI2ZWJz0WZCCExNm78pc7//ThbOnycHDxyQwQP7mxNLtevU9ffQ8AjMnb0xf/bG/Nkb8xdgaBAUOA2CnI13/vrrL9OcRgMrXROZOnVqkwnUBjoaoGmTHG2aoxk2LQ/Vsk7tFBsZGijqmkSl6xa1IY8+76O+XzOuWvqq6zb1tbX0VBsZacdYFdVx6RYs33zzjTRs2NAEnFrimjFjRhNgd+7c2QStGnB/8MEHpjmRe4b1u+++M8GvBpz6s+iYtDmQexmsrgv98ccfpVy5cq4AVINCXbN6v06/EEmdIpF8MaiZpEuVRC5euSHb9x2Vmu3GyS9rd8tzxXKYLVDUzh/6e3xfrhp95cjxc34aNR6mWvUacv7cORk3ZpScOXNacuXOI+MmTpaUlBIFPObO3pg/e2P+7I35Q6ALckS2Uw/w/8Uv0sHfQ4APzq8f4+8hAAAARFqYX9NjkRe/2gi/vv71JV0k0Nhk6gAAAAAggAVokx5/CsziXgAAAACArZHZBAAAAABfBWiTHn/iNwIAAAAAsByZTQAAAADwFWs2vZDZBAAAAABYjmATAAAAAGA5ymgBAAAAwFc0CPLCbwQAAAAAYDkymwAAAADgKzKbXviNAAAAAAAsR7AJAAAAALAcZbQAAAAA4Cv22fRCZhMAAAAAYDkymwAAAADgKxoEeeE3AgAAAACwHMEmAAAAAMBylNECAAAAgK9oEOSFzCYAAAAAwHJkNgEAAADAVzQI8sJvBAAAAABgOYJNAAAAAIDlKKMFAAAAAF/RIMgLmU0AAAAAgOXIbAIAAACAj4LIbHohswkAAAAAsBzBJgAAAADAcpTRAgAAAICPKKP1RmYTAAAAAGA5MpsAAAAA4CsSm17IbAIAAAAALEewCQAAAACwHGW0AAAAAOAjGgR5I7MJAAAAALAcmU0AAAAA8BGZTW9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPARZbTeyGwCAAAAACxHZhMAAAAAfERm0xuZTQAAAACA5Qg2AQAAAACWo4wWAAAAAHxFFa0XMpsAAAAAAMuR2QQAAAAAH9EgyBuZTQAAAACA5Qg2AQAAAACWo4wWAAAAAHxEGa03gk1E2fn1Y/w9BPggefEO/h4CfMDxBwAA7IJgEwAAAAB8RGbTG2s2AQAAAACWI9gEAAAAAFiOMloAAAAA8BFltN7IbAIAAAAALEdmEwAAAAB8RWLTC5lNAAAAAIDlCDYBAAAAAJajjBYAAAAAfESDIG9kNgEAAAAAliOzCQAAAAA+IrPpjcwmAAAAAMByBJsAAAAAAMtRRgsAAAAAPqKM1huZTQAAAACA5chsAgAAAICvSGx6IbMJAAAAALAcwSYAAAAAwHKU0QIAAACAj2gQ5I3MJgAAAADAcmQ2AQAAAMBHZDa9kdkEAAAAAFiOYBMAAAAAYDnKaAEAAADAR5TReiOzCQAAAACwHJlNAAAAAPARmU1vZDYBAAAAAJYj2AQAAAAAWI5gEwAAAAB8FeTnSxQMHTpUihcvLokTJ5Y0adJI7dq1Zc+ePR6PqVixoikNdr+0bds2Ki9DsAkAAAAAscnKlSulffv2smbNGvn555/l9u3b8uKLL8rVq1c9HteqVSs5fvy46/Lxxx9H6XVoEAQAAAAAsahB0JIlSzyuT5061WQ4N27cKOXLl3fdniBBAkmXLt1jvw6ZTQAAAACIxS5evGj+TZEihcftM2bMkFSpUkn+/PklPDxcrl27FqXnJbMJAAAAADZ38+ZNc3EXGhpqLg9z79496dSpk5QtW9YElU6vvfaaZMqUSTJkyCBbt26Vnj17mnWdc+fOjfSYCDYBAAAAwOZltEOHDpUBAwZ43NavXz/p37//Q79P125u375d/vjjD4/bW7du7fq6QIECkj59ennhhRfkwIEDki1btkiNiWATAAAAAGwuPDxcunTp4nHbo7KaHTp0kEWLFslvv/0mTz/99EMfW7JkSfPv/v37CTYBAAAAILZkNkMjUTLr5HA4pGPHjjJv3jxZsWKFZMmS5ZHfs3nzZvOvZjgji2ATAAAAAGKR9u3by8yZM2XBggVmr80TJ06Y25MmTSrx48c3pbJ6f40aNSRlypRmzWbnzp1Np9qCBQtG+nUINgEAAAAgFhk/frz5t2LFih63T5kyRd544w0JCQmRZcuWyaeffmr23nzmmWekXr168v7770fpdQg2AQAAAMBX9tlmU7SM9mE0uFy5cqXPr8M+mwAAAAAAy5HZBAAAAACbNwgKRGQ2AQAAAACWI7MJAAAAAD4is+mNzCYAAAAAwHIEmwAAAAAAyxFsxiJTp06VZMmS+XsYAAAAQIwso/XnJRARbD7AiRMnpGPHjpI1a1YJDQ01e83UrFlTli9f7vNzX7p0SXr37i25c+eWsLAwSZcunVSuXFnmzp37yD1vEL1mzZwh1as8L8WLFJAmjRrItq1b/T0kRNCqQTlZ9224nPx9mLmsmNZVXiyb19yXPEkCGdGzgWyZ10fOrR4hexcPlOE96kuSRGH+HjYegWPP3pg/e2P+7I35QyAj2LyPw4cPS7FixeSXX36RYcOGybZt22TJkiVSqVIlad++/WM95927d+XevXty4cIFKVOmjHz11VcSHh4uf/31l/z222/SsGFD6dGjh1y8ePG+33/r1i0ffyo8ypKfFssnHw+VNu3ay6zZ8yRXrtzydpuWcvbsWX8PDW6OnrwgfUYvkDJNPpayTYbJinV7ZfbI1pInazpJnzqpuYSPnCfFGnwgrfp9LVXK5JUJ/Zr4e9h4CI49e2P+7I35szfmL7CQ2fRGsHkf7dq1MxO2bt06qVevnuTMmVPy5csnXbp0kTVr1pjHjBgxQgoUKCAJEyY0WU/9nitXrniVrC5cuFDy5s1rsqNHjhyR9957zwSza9eulebNm5v79PlbtWolmzdvlkSJEpnvz5w5swwaNEiaNWsmSZIkkdatW5vbe/bsaR6fIEECk3Xt06eP3L592/W6W7ZsMUFx4sSJzfdp0LxhwwaPn2/p0qWSJ08e81rVqlWT48ePP6HfbGCbPm2K1K3/qtSuU0+yZc8u7/cbYDLP8+fO8ffQ4Gbxb9tl6R875cCR07L/yCnpP/YHuXLtppQomEV2HjgujbtNNo859O8ZWbl+r/Qf84PUKJ9f4sThz12g4tizN+bP3pg/e2P+EOj49BXBuXPnTBZTM5gaSEbkXPMYHBwso0aNkh07dsi0adNMFlQzk+6uXbsmH330kUyePNk8Lk2aNDJr1ixp0qSJZMiQweu5NfiLG/f/dqP55JNPpFChQrJp0yYTVCoNIjWQ3blzp3z22WcyadIkGTlypOt79LmffvppWb9+vWzcuFF69eol8eLF8xiTPu/06dNNRlUD4G7duklsd/vWLdm1c4eUKl3GdZvOcalSZWTrlk1+HRseLDg4SBpULSYJ44fI2q2H7vuYJInD5NLVG3L37r0nPj48GseevTF/9sb82RvzBztgn80I9u/fb9ZN6nrKh+nUqZPra81CDh48WNq2bSvjxo1z3a4ZR72uAaM6deqUnD9//pHP7fT8889L165dPW57//33PV5XA0UNYJ2BrgaP3bt3d71Gjhw5PL5fxzRhwgTJli2bud6hQwcZOHCgxHbnL5w3pc4pU6b0uF2vHzp00G/jwv3ly57BrNUMC4krV67flIZdJ8nugye8HpcyWUIJb1Vdvpyzyi/jxKNx7Nkb82dvzJ+9MX8BKDArWf2KYDOCyDboWbZsmQwdOlR2795tGv7cuXNHbty4YTKHWuKqQkJCpGDBglF+bqdnn33W67Zvv/3WZFQPHDhgynb1dbVc1klLfd966y2TudSmQw0aNHAFlkrH5n49ffr0Jgh+kJs3b5qLO0ecUFMWDPjL3sMnpWSjoZI0UXypU7mITBrYVF586zOPgDNxwjCZN+pt2XXwuAye+KNfxwsAABAbUUYbgWYCdb2mBpEPomsuX375ZRNIzpkzx5Srjh071quRT/z48T0W66ZOndqU4T7sud1FLONdvXq1KZOtUaOGLFq0yJTXaldb99fs37+/Kdl96aWXTGmvrgmdN2+e6373klql43tYEKwBddKkST0uwz4aKjFN8mTJJU6cOF4L6vV6qlSp/DYu3N/tO3fl4D9nZNOuf6Tv6IWybe9Rad+4ouv+RAlCZeHYdnL52g1p2GWS3LlDCW2g4tizN+bP3pg/e2P+Ag8NgrwRbEaQIkUKqVq1qgker1696nW/dpPV4FI7yw4fPlxKlSplGvYcO3bskc+tdfSNGjWSGTNm3Pfxzkzlg6xatUoyZcpkAkzNempg/Pfff3s9TsfTuXNn+d///id169aVKVOmyOPSjrnaIdf90r1nuMQ08UJCJE/efLJ2zWrXbTrHa9euloKFivh1bHi04KAgCQ2J68poLhrfQW7dviv1O02Um7cefEzB/zj27I35szfmz96YP9gBweZ9aKCpNfAlSpQwmct9+/bJrl27TPlq6dKlJXv27Gbt4+jRo+XgwYOmZFXXQUbGkCFDTPfakiVLmu1PtNGPPv+XX34pRYoU8ehoG5EGl7omU9doahmtjsc9a3n9+nWzBnPFihUmCP3zzz9NoyDtPPu4tFxWy3TdLzG1hLZp8zdl7vffycL58+TggQMyeGB/8zutXaeuv4cGNwM7viJli2aTjOlTmLWber38szlk1uIN/wWa49pLgrAQaTtghiRJGCZpUyY2F20mhMDEsWdvzJ+9MX/2xvwh0LFm8z50SxHd/1IDQ23Qo1uDaAmsbiMyfvx40/BHtz7RTrOa+StfvrwpN9VtSiKTOdXtUz788EPTVEiDwuTJk5ttVHRPTy1TfZBXXnnFZCw1oNR1lFoqq11qtXRWOUspdBwnT540JRSa2RwwYIClv5+Yqlr1GnL+3DkZN2aUnDlzWnLlziPjJk6WlJSiBJTUKRLJF4OaSbpUSeTilRuyfd9RqdlunPyydrc8VyyH2QJF7fzhv+PCKVeNvnLk+Dk/jRoPw7Fnb8yfvTF/9sb8BZZALWX1pyBHVLvWINa7QVWirSUv3sHfQ4APzq8f4+8hAADwRIXZJD2WretPfn39A8OrS6CxydQBAAAAQOAisemNNZsAAAAAAMsRbAIAAAAALEcZLQAAAAD4iAZB3shsAgAAAAAsR2YTAAAAAHxEYtMbmU0AAAAAgOUINgEAAAAAlqOMFgAAAAB8RIMgb2Q2AQAAAACWI7MJAAAAAD4isemNzCYAAAAAwHIEmwAAAAAAy1FGCwAAAAA+Cg6mjjYiMpsAAAAAAMuR2QQAAAAAH9EgyBuZTQAAAACA5Qg2AQAAAACWo4wWAAAAAHwURB2tFzKbAAAAAADLkdkEAAAAAB+R2PRGZhMAAAAAYDmCTQAAAACA5SijBQAAAAAf0SDIG5lNAAAAAIDlyGwCAAAAgI/IbHojswkAAAAAsBzBJgAAAADAcpTRAgAAAICPqKL1RmYTAAAAAGA5MpsAAAAA4CMaBHkjswkAAAAAsBzBJgAAAADAcpTRAgAAAICPqKL1RmYTAAAAAGA5MpsAAAAA4CMaBHkjswkAAAAAsBzBJgAAAADAcpTRAgAAAICPqKL1RmYTAAAAAGA5MpsAAAAA4CMaBHkjswkAAAAAsBzBJgAAAADAcpTRAgAAAICPqKL1RmYTAAAAAGA5MpsAAAAA4CMaBHkjswkAAAAAsBzBJgAAAADAcpTRArHM+fVj/D0E+CB58Q7+HgJ8wPEHADEXVbTeyGwCAAAAACxHZhMAAAAAfESDIG9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPARVbTeyGwCAAAAACxHZhMAAAAAfESDIG9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPARVbTeyGwCAAAAACxHZhMAAAAAfESDIG9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPARZbTeyGwCAAAAACxHZhMAAAAAfERi0xuZTQAAAACA5Qg2AQAAAACWo4wWAAAAAHxEgyBvZDYBAAAAAJYj2AQAAAAAH2li05+XqBg6dKgUL15cEidOLGnSpJHatWvLnj17PB5z48YNad++vaRMmVISJUok9erVk5MnT0bpdQg2AQAAACAWWblypQkk16xZIz///LPcvn1bXnzxRbl69arrMZ07d5YffvhBZs+ebR5/7NgxqVu3bpRehzWbAAAAABCL1mwuWbLE4/rUqVNNhnPjxo1Svnx5uXjxonzxxRcyc+ZMef75581jpkyZInny5DEBaqlSpSL1OmQ2AQAAACAWu3jxovk3RYoU5l8NOjXbWblyZddjcufOLRkzZpTVq1dH+nnJbAIAAACAzd28edNc3IWGhprLw9y7d086deokZcuWlfz585vbTpw4ISEhIZIsWTKPx6ZNm9bcF1lkNgEAAADA5g2Chg4dKkmTJvW46G2Poms3t2/fLrNmzbL8d0JmEwAAAABsLjw8XLp06eJx26Oymh06dJBFixbJb7/9Jk8//bTr9nTp0smtW7fkwoULHtlN7Uar90UWwSYAAAAA+CjYzw2CQiNRMuvkcDikY8eOMm/ePFmxYoVkyZLF4/5ixYpJvHjxZPny5WbLE6Vboxw5ckRKly4d6TERbAIAAABALNK+fXvTaXbBggVmr03nOkwtvY0fP775t2XLliZTqk2DkiRJYoJTDTQj24lWEWwCAAAAQCwyfvx482/FihU9btftTd544w3z9ciRIyU4ONhkNrXxUNWqVWXcuHFReh2CTQAAAADwkY222RQto32UsLAwGTt2rLk8LrrRAgAAAAAsR2YTAAAAAHwUZKfU5hNCZhMAAAAAYDmCTQAAAACA5SijBQAAAAAfBVNF64XMJgAAAADAcmQ2AQAAAMBHNAjyRmYTAAAAAGA5gk0AAAAAgOUoowUAAAAAH1FF643MJgAAAADAcmQ2AQAAAMBHQUJqMyIymwAAAAAAyxFsQjJnziyffvqpv4cBAAAAIAaJccHmiRMnpGPHjpI1a1YJDQ2VZ555RmrWrCnLly/36Xn79+9v9s7RS5w4cczztm7dWs6dO2fZ2OF/s2bOkOpVnpfiRQpIk0YNZNvWrf4eEqKA+Qt8rRqUk3XfhsvJ34eZy4ppXeXFsnnNfcmTJJARPRvIlnl95NzqEbJ38UAZ3qO+JEkU5u9h4xE49uyN+bM35i9wBAf59xKIYlSwefjwYSlWrJj88ssvMmzYMNm2bZssWbJEKlWqJO3bt3+s57x7967cu3fPfJ0vXz45fvy4HDlyRKZMmWKe++2337b4p4C/LPlpsXzy8VBp0669zJo9T3Llyi1vt2kpZ8+e9ffQEAnMnz0cPXlB+oxeIGWafCxlmwyTFev2yuyRrSVP1nSSPnVScwkfOU+KNfhAWvX7WqqUySsT+jXx97DxEBx79sb82Rvzh0AXo4LNdu3amczjunXrpF69epIzZ04TIHbp0kXWrFljHjNixAgpUKCAJEyY0GQn9XuuXLnieo6pU6dKsmTJZOHChZI3b16THdXgUsWNG1fSpUsnTz31lFSuXFkaNGggP//8s8cYJk+eLHny5JGwsDDJnTu3jBs3ziMY1vHNnTvXBMAJEiSQQoUKyerVqz2e448//pDnnntO4sePb8b4zjvvyNWrV819Y8aMkfz587seO3/+fPOcEyZMcN2mY3v//ffN1wcOHJBatWpJ2rRpJVGiRFK8eHFZtmyZxb/5mGH6tClSt/6rUrtOPcmWPbu832+Amcf5c+f4e2iIBObPHhb/tl2W/rFTDhw5LfuPnJL+Y3+QK9duSomCWWTngePSuNtk85hD/56Rlev3Sv8xP0iN8vklTpwY9XYVo3Ds2RvzZ2/MX2BxVkH66xKIYsy7t5azaqZRM5gaSEakAaQKDg6WUaNGyY4dO2TatGkmC9qjRw+Px167dk0++ugjEzjq49KkSeP1fBo4Ll26VEJCQly3zZgxQ/r27StDhgyRXbt2yQcffCB9+vQxr+Oud+/e0q1bN9m8ebMJiBs3bix37txxBYfVqlUzwfLWrVvl22+/NcFnhw4dzP0VKlSQnTt3yunTp831lStXSqpUqWTFihXm+u3bt03wWrFiRXNdA+kaNWqYMuJNmzaZ59ayYmcAjf/cvnVLdu3cIaVKl3Hdpv+tlCpVRrZu2eTXseHRmD97Cg4OkgZVi0nC+CGyduuh+z4mSeIwuXT1hty9+1+FCQILx569MX/2xvzBDmLM1if79+8Xh8NhsokP06lTJ4/GOIMHD5a2bdt6ZCA1YNPrmnV0p2W5mh3U0tobN264MqVO/fr1k+HDh0vdunXN9SxZspjAcOLEidK8eXPX4zTQfOmll8zXAwYMMNlXHb+OfejQodKkSRPXOHPkyGGCYw0yx48fb7KaKVKkMEFm/fr1TZDZtWtX+eyzz8zjNaur4y9T5r8/PPozuP8cgwYNknnz5pnMrTOAhcj5C+fNvKZMmdLjdr1+6NBBv40LkcP82Uu+7BnMWs2wkLhy5fpNadh1kuw+eMLrcSmTJZTwVtXlyzmr/DJOPBrHnr0xf/bG/MEOYkywqYFmZGgJqQZ0u3fvlkuXLpmMogaOms3Uslal2cqCBQt6fW+uXLlMkKaP//rrr01mUpsRKS1z1axky5YtpVWrVq7v0edPmjSpx/O4P3f69OnNv6dOnTLB5pYtW0xGU7Ok7j+brhs9dOiQKdEtX768CTK1XFaDWS0F/vjjj83PpEGolso6fxbNbGpzox9//NGsN9XxXL9+PdKZzZs3b5qLx+86TqgpLwaAx7H38Ekp2WioJE0UX+pULiKTBjaVF9/6zCPgTJwwTOaNelt2HTwugyf+6NfxAgAQGQFayepXMaaMVjOAWqusAdeDaOnryy+/bIK9OXPmyMaNG2Xs2LHmvlu3brkep2sl71f3rEFo9uzZTXbxww8/NF1pNTOpnOs+J02aZIJQ52X79u2u9aJO8eLFc33tfB1nEyJ9njZt2ng8hwag+/btk2zZspnHaImsBpu///67FClSRJIkSeIKQDXY1CyoexZVM5la0quP1+fTNavuP+/DaGCuwbL7ZdhHQyWmSZ4suZnPiAvq9bqWKSOwMX/2cvvOXTn4zxnZtOsf6Tt6oWzbe1TaN/6v9F8lShAqC8e2k8vXbkjDLpPkzh1KaAMVx569MX/2xvzBDmJMsKmlpVWrVjXBo7OZjrsLFy6Y4FKDOi11LVWqlFkveezYscd+TW3C88knn5jn0AY8GTJkkIMHD5qA1P2i5bSRVbRoUZOtjPgcenGuD3Wu25w9e7Zrbab+q1nbP//803Wb0utvvPGG1KlTxwSZ2uBIg+7ICg8Pl4sXL3pcuvcMl5gmXkiI5MmbT9au+b9mTfrfytq1q6VgoSJ+HRsejfmzt+CgIAkNievKaC4a30Fu3b4r9TtNlJu3/lvPjsDEsWdvzJ+9MX+B+X7mz0sgijHBptJAU2vXS5QoYTKXmg3URj265rF06dImYNP1jKNHjzZB4fTp0z26uEaVPqdmSTVrqDTLqZlAfb29e/eaNZ66RYr7us5H6dmzp6xatcqsp9QspP4MCxYs8Fhfqa+ZPHlymTlzpkewqZ1pteS1bNmyHhlf7X7rzJC+9tprrixqZGi5rGZO3S8xtYS2afM3Ze7338nC+fPk4IEDMnhgf1NyXLvOf2twEdiYP3sY2PEVKVs0m2RMn8Ks3dTr5Z/NIbMWb/gv0BzXXhKEhUjbATMkScIwSZsysbloMyEEJo49e2P+7I35Q6CLMWs2VdasWeWvv/4y3WC1aY6uUUydOrXZe1Ob62ijHA38tNOsZuy09FSDw2bNmj32a3bu3NlkDjVIfOutt8xaSd3js3v37qYrrmYT3ZsSPYoGkloKqx1rdfsTXa+p5bMNGzb0KL3V+3QdZrly5Vzfp4Ggrit178arP2+LFi1MwyAtqdBx6lpVeKtWvYacP3dOxo0ZJWfOnJZcufPIuImTJSWlKLbA/NlD6hSJ5ItBzSRdqiRy8coN2b7vqNRsN05+WbtbniuWw2yBonb+0N/j+3LV6CtHjp/z06jxMBx79sb82Rvzh0AX5IhsZx3g/7tBVRvgN8mL00Xazs6vH+PvIQCA7YTZJD1W78uNfn39OS2KSaCJUWW0AAAAAIDAYJPzBAAAAAAQuO63m0VsR2YTAAAAAGA5gk0AAAAAgOUoowUAAAAAH1FF643MJgAAAADAcmQ2AQAAAMBHwaQ2vZDZBAAAAABYjmATAAAAAGA5ymgBAAAAwEcU0XojswkAAAAAsByZTQAAAADwURANgryQ2QQAAAAAWI5gEwAAAADgnzLarVu3RvoJCxYs6Mt4AAAAAMB2gqmifbxgs3DhwqYG2eFw3Pd+53367927dyPzlAAAAACA2B5sHjp0KPpHAgAAAAA2RYOgxww2M2XKFJmHAQAAAADw+A2Cpk+fLmXLlpUMGTLI33//bW779NNPZcGCBY/zdAAAAACA2B5sjh8/Xrp06SI1atSQCxcuuNZoJkuWzAScAAAAABDbaBWtPy8xItgcPXq0TJo0SXr37i1x4sRx3f7ss8/Ktm3brB4fAAAAACCmrtmM2CyoSJEiXreHhobK1atXrRoXAAAAANgGDYIsyGxmyZJFNm/e7HX7kiVLJE+ePFF9OgAAAABADBTlzKau12zfvr3cuHHD7K25bt06+eabb2To0KEyefLk6BklAAAAACBmB5tvvfWWxI8fX95//325du2avPbaa6Yr7WeffSaNGjWKnlECAAAAQAALporW92BTNWnSxFw02Lxy5YqkSZPmcZ4GAAAAABBDPVawqU6dOiV79uxxLYZNnTq1leMCAAAAANugQZAFDYIuX74sTZs2NaWzFSpUMBf9+vXXX5eLFy9G9ekAAAAAADFQ8OOs2Vy7dq38+OOPcuHCBXNZtGiRbNiwQdq0aRM9owQAAAAAxOwyWg0sly5dKuXKlXPdVrVqVZk0aZJUq1bN6vEBAAAAQMCjiNaCzGbKlCkladKkXrfrbcmTJ4/q0wEAAAAAYqAoB5u65YnutXnixAnXbfp19+7dpU+fPlaPDwAAAAACXnBQkF8vti2jLVKkiEd3pX379knGjBnNRR05ckRCQ0Pl9OnTrNsEAAAAAEQu2Kxdu3b0jwQAAAAAELuCzX79+kX/SAAAAADApgK0ktVeazYBAAAAALB865O7d+/KyJEj5bvvvjNrNW/duuVx/7lz56L6lAAAAABga+49bvCYmc0BAwbIiBEjpGHDhnLx4kXTmbZu3boSHBws/fv3j+rTAQAAAABioCgHmzNmzJBJkyZJ165dJW7cuNK4cWOZPHmy9O3bV9asWRM9owQAAAAAxOxgU/fULFCggPk6UaJEJrupXn75Zfnxxx+tHyEAAAAABDitovXnJUYEm08//bQcP37cfJ0tWzb53//+Z75ev3692WsTAAAAAIAoNwiqU6eOLF++XEqWLCkdO3aU119/Xb744gvTLKhz587RM0oAAAAACGDBgZpetFOw+eGHH7q+1iZBmTJlklWrVkmOHDmkZs2aVo8PAAAAABAb99ksVaqU6Uirmc4PPvjAmlEBAAAAAGzN52DTSddx9unTx6qnAwAAAADboEFQNAabAAAAAAA89ppNAAAAAICnoEBNL/oRmU0AAAAAgP8ym9oE6GFOnz5txXgAAAAAALEp2Ny0adMjH1O+fHlfxwMAeIjz68f4ewjwQfLiHfw9BPiA4w/Aw1Ay6kOw+euvv0b2oQAAAACAWI4GQQAAAADgIxoEeSPbCwAAAACwHJlNAAAAAPBRMIlNL2Q2AQAAAACWI9gEAAAAAARGsPn777/L66+/LqVLl5ajR4+a26ZPny5//PGH1eMDAAAAAFuU0frzEiOCzTlz5kjVqlUlfvz4Zu/NmzdvmtsvXrwoH3zwQXSMEQAAAABgM1EONgcPHiwTJkyQSZMmSbx48Vy3ly1bVv766y+rxwcAAAAAttj6xJ+XGBFs7tmzR8qXL+91e9KkSeXChQtWjQsAAAAAYGNRDjbTpUsn+/fv97pd12tmzZrVqnEBAAAAAGLTPputWrWSd999V7788kuTrj127JisXr1aunXrJn369ImeUQIAAABAAAvUJj22CjZ79eol9+7dkxdeeEGuXbtmSmpDQ0NNsNmxY8foGSUAAAAAIGYHm5rN7N27t3Tv3t2U0165ckXy5s0riRIlip4RAgAAAECAC9AePfbbZ1OFhISYILNEiRIEmgAAAABgE7/99pvUrFlTMmTIYJKJ8+fP97j/jTfe8Op2W61atejPbFaqVOmhrXV/+eWXKA8CAAAAAPBkXL16VQoVKiQtWrSQunXr3vcxGlxOmTLFdV2XTkZ7sFm4cGGP67dv35bNmzfL9u3bpXnz5lEeAAAAAADYXbCN6mirV69uLg+jwaXuROKLKAebI0eOvO/t/fv3N+s3AQAAAABP1s2bN80lYsD4OBlJtWLFCkmTJo0kT55cnn/+eRk8eLCkTJnyyazZjOj1118326EAAAAAQGwT7OfL0KFDJWnSpB4Xve1xaAntV199JcuXL5ePPvpIVq5caTKhd+/ejd7M5oPoXpthYWFWPR0AAAAAIJLCw8OlS5cuHrc9blazUaNGrq8LFCggBQsWlGzZsplsp26BGW3BZsQFpA6HQ44fPy4bNmyQPn36RPXpAAAAAAA+8qVk9lGyZs0qqVKlMltfRmuwqelYd8HBwZIrVy4ZOHCgvPjii1F9OgAAAACwPRv1B4qyf//9V86ePSvp06eP0vdFKdjUGt0333zTpFJ1oSgAAAAAwF6uXLlispROhw4dMjuMpEiRwlwGDBgg9erVM91oDxw4ID169JDs2bNL1apVoy/YjBMnjsle7tq1i2ATAAAAAGy49cmGDRukUqVKruvOtZ66leX48eNl69atMm3aNLlw4YJkyJDBxICDBg2KcplulMto8+fPLwcPHpQsWbJE9VsBAAAAAH5WsWJF03vnQZYuXWrJ60R56xPdX6Vbt26yaNEi0xjo0qVLHhcAAAAAACKd2dQGQF27dpUaNWqY66+88ooEuaWKNTLW61HdewUAAAAA7M5GVbSBF2zqItG2bdvKr7/+Gr0jAgAAAADEnmDTWdNboUKF6BwPAAAAANhOMJlN39ZsupfNAgAAAABgSTfanDlzPjLgPHfuXFSeEgAAAAAQ24NNXbeZNGnS6BsNAAAAANiQnfbZDMhgs1GjRpImTZroGw0AAAAAIHYFm6zXBAAAAID7I1zyoUGQsxstAAAAAACWZTbv3bsX2YcCAAAAAGK5KK3ZBAAAAAB4Y59NH/fZBAAAAAAgMshsAgAAAICPgoTUZkRkNgEAAAAAliPYBAAAAABYjjJaAAAAAPARDYK8kdkEAAAAAFiOzCYAAAAA+IjMpjcymwAAAAAAyxFsBrjDhw9LUFCQbN682afnuXbtmtSrV0+SJElinu/ChQuWjREAAAAAIiLYjKQTJ05Ix44dJWvWrBIaGirPPPOM1KxZU5YvX/7Yz5k5c2YT+D3o8sYbb1g2/mnTpsnvv/8uq1atkuPHj8v58+ctCWJjmlkzZ0j1Ks9L8SIFpEmjBrJt61Z/DwlRwPzZF3NnD60alJN134bLyd+HmcuKaV3lxbJ5zX3JkySQET0byJZ5feTc6hGyd/FAGd6jviRJFObvYeMROP7sjfkLHA/7XB/0BC6BiGAzktnFYsWKyS+//CLDhg2Tbdu2yZIlS6RSpUrSvn37x3rOu3fvytq1a03gp5c5c+aY2/fs2eO67bPPPrPsZzhw4IDkyZNH8ufPL+nSpQvY/yD9aclPi+WTj4dKm3btZdbseZIrV255u01LOXv2rL+Hhkhg/uyLubOPoycvSJ/RC6RMk4+lbJNhsmLdXpk9srXkyZpO0qdOai7hI+dJsQYfSKt+X0uVMnllQr8m/h42HoLjz96YPwQ6gs1IaNeunQnO1q1bZ0pRc+bMKfny5ZMuXbrImjVrzGNGjBghBQoUkIQJE5qsp37PlStXXM8xdepUSZYsmSxcuFDy5s1rsqPXr183gZ9eUqRIYR6XJk0a121JkyZ1ff/BgwdNcJsgQQIpVKiQrF692mOMf/zxhzz33HMSP3588/rvvPOOXL161dxXsWJFGT58uPz222/m59DrWbJkMfcVKVLEdVtsN33aFKlb/1WpXaeeZMueXd7vN0DCwsJk/tz/TgQgsDF/9sXc2cfi37bL0j92yoEjp2X/kVPSf+wPcuXaTSlRMIvsPHBcGnebbB5z6N8zsnL9Xuk/5gepUT6/xInDx41AxfFnb8xf4DUI8uclEPHX/xHOnTtnspiawdRAMiINIFVwcLCMGjVKduzYYUpWNQvao0cPr3WTH330kUyePNk8TgPLyOrdu7d069bNlL1qsNu4cWO5c+eOK2tZrVo1Ewhv3bpVvv32WxN8dujQwdw/d+5cadWqlZQuXdpkTPW6Bs5q2bJlrttis9u3bsmunTukVOkyrtt0TkuVKiNbt2zy69jwaMyffTF39hUcHCQNqhaThPFDZO3WQ/d9TJLEYXLp6g25e/feEx8fHo3jz96YP9gBW588wv79+8XhcEju3Lkf+rhOnTp5rMUcPHiwtG3bVsaNG+e6/fbt2+a6ZiajSgPNl156yXw9YMAAk1nVsem4hg4dKk2aNHGNIUeOHCbwrVChgowfP95kTTUjGhISYjKm6tKlS+bflClTum6Lzc5fOG9Km/X34U6vHzp00G/jQuQwf/bF3NlPvuwZzFrNsJC4cuX6TWnYdZLsPnjC63EpkyWU8FbV5cs5q/wyTjwax5+9MX+wA4LNR9BAMzI0Q6hB3+7du00gp1nHGzdumGymBnpKg72CBQs+1jjcvy99+vTm31OnTplgc8uWLSajOWPGDI9x37t3Tw4dOmTWaj6umzdvmos7R5xQUwYMAIh99h4+KSUbDZWkieJLncpFZNLApvLiW595BJyJE4bJvFFvy66Dx2XwxB/9Ol4AeFJoieKNMtpH0CyhrmnUIPJhDYRefvllExBqo5+NGzfK2LFjzX23bt1yPU7XUz5uY5548eK5vnY+hwaTSteGtmnTxpTYOi8agO7bt0+yZcsmvtAAWteOul+GfTRUYprkyZJLnDhxvBbU6/VUqVL5bVyIHObPvpg7+7l9564c/OeMbNr1j/QdvVC27T0q7Rv/37r/RAlCZeHYdnL52g1p2GWS3LlDCW2g4vizN+YPdkCw+Qhaglq1alUTPDob7rjT/So1uNTAT5vwlCpVyqypPHbs2BMbY9GiRWXnzp2SPXt2r4tmU+/HebuWXzxMeHi4XLx40ePSvWe4xDTxQkIkT958snbN/zVe0jldu3a1FCxUxK9jw6Mxf/bF3NlfcFCQhIbEdWU0F43vILdu35X6nSbKzVv/9RZAYOL4szfmLzD/HvrzEogINiNBA00NykqUKGEyl5ox3LVrl1kXqU13NKjT9ZijR482XWOnT58uEyZMeGLj69mzp9k/UxsCaVZTx7dgwQJXg6D70eZEmmnV5kcnT540QeT9aLlskiRJPC4xtYS2afM3Ze7338nC+fPk4IEDMnhgf9MxuHaduv4eGiKB+bMv5s4+BnZ8RcoWzSYZ06cwazf1evlnc8isxRv+CzTHtZcEYSHSdsAMSZIwTNKmTGwu2kwIgYnjz96YPwQ61mxGQtasWeWvv/6SIUOGSNeuXU331tSpU5u9N7UBjzb80a1PtNOsZgLLly9vyk+bNWv2RMan5bsrV640HWt1+xNdr6nlsw0bNnzg98SNG9cEywMHDpS+ffua71uxYoXEZtWq15Dz587JuDGj5MyZ05Irdx4ZN3GypKQUxRaYP/ti7uwjdYpE8sWgZpIuVRK5eOWGbN93VGq2Gye/rN0tzxXLYbZAUTt/6O/xfblq9JUjx8/5adR4GI4/e2P+EOiCHJHtgAP8fzeoigKAx5K8+IMrThD4zq8f4+8hALFSmE3SY6P+uP82UE/KO+X+O+EXSCijBQAAAABYzibnCQAAAAAgcAVojx6/IrMJAAAAALAcwSYAAAAAwHKU0QIAAACAj4KFOtqIyGwCAAAAACxHZhMAAAAAfESDIG9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPBRMGW0XshsAgAAAAAsR2YTAAAAAHwUTIcgL2Q2AQAAAACWI9gEAAAAAFiOMloAAAAA8BFVtN7IbAIAAAAALEdmEwAAAAB8RIMgb2Q2AQAAAACWI9gEAAAAAFiOMloAAAAA8BFVtN7IbAIAAAAALEdmEwAAAAB8RBbPG78TAAAAAIDlCDYBAAAAAJajjBYAAAAAfBREhyAvZDYBAAAAAJYjswkAAAAAPiKv6Y3MJgAAAADAcgSbAAAAAADLUUYLAAAAAD4KpkGQFzKbAAAAAADLkdkEAAAAAB+R1/RGZhMAAAAAYDkymwAAAADgI5ZseiOzCQAAAACwHMEmAAAAAMBylNECAAAAgI+CqKP1QmYTAAAAAGA5MpsAAAAA4COyeN74nQAAAAAALEewCQAAAACwHGW0AAAAAOAjGgR5I7MJAAAAALAcmU0AAAAA8BF5TW9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPARDYK8kdkEAAAAAFiOzCYAAE/I+fVj/D0E+CB58Q7+HgIeE8cengSyeN74nQAAAAAALEewCQAAAACwHGW0AAAAAOAjGgR5I7MJAAAAALAcmU0AAAAA8BF5TW9kNgEAAAAAliPYBAAAAABYjmATAAAAAHyk/YH8eYmK3377TWrWrCkZMmQwjY3mz5/vcb/D4ZC+fftK+vTpJX78+FK5cmXZt2+fRBXBJgAAAADEIlevXpVChQrJ2LFj73v/xx9/LKNGjZIJEybI2rVrJWHChFK1alW5ceNGlF6HBkEAAAAA4KNgG7UIql69urncj2Y1P/30U3n//felVq1a5ravvvpK0qZNazKgjRo1ivTrkNkEAAAAABiHDh2SEydOmNJZp6RJk0rJkiVl9erVEhVkNgEAAADA5m7evGku7kJDQ80lKjTQVJrJdKfXnfdFFplNAAAAALB5g6ChQ4eaDKT7RW/zJzKbAAAAAGBz4eHh0qVLF4/boprVVOnSpTP/njx50nSjddLrhQsXjtJzkdkEAAAAAB8F+fl/oaGhkiRJEo/L4wSbWbJkMQHn8uXLXbddunTJdKUtXbp0lJ6LzCYAAAAAxCJXrlyR/fv3ezQF2rx5s6RIkUIyZswonTp1ksGDB0uOHDlM8NmnTx+zJ2ft2rWj9DoEmwAAAAAQi2zYsEEqVarkuu4sv23evLlMnTpVevToYfbibN26tVy4cEHKlSsnS5YskbCwsCi9TpBDN1IBouDGHX+PAACAJy958Q7+HgIe0/n1Y/w9BPggzCbpscU7Tvn19WvkSyOBhjWbAAAAAADL2eQ8AQAAAAAErmAJ8vcQAg6ZTQAAAACA5Qg2AQAAAACWo4wWAAAAAHwURBWtFzKbAAAAAADLkdkEAAAAAB+R2fRGZhMAAAAAYDmCTQAAAACA5SijBQAAAAAfBbHPphcymwAAAAAAy5HZBAAAAAAfBZPY9EJmEwAAAABgOYJNAAAAAIDlKKMFAAAAAB/RIMgbmU0AAAAAgOXIbAIAAACAj4JIbHohswkAAAAAsBzBJgAAAADAcpTRAgAAAICPaBDkjcwmAAAAAMByZDYBAAAAwEfBJDa9kNkEAAAAAFiOYBMAAAAAYDnKaAEAAADARzQI8kZmEwAAAABgOTKbAAAAAOCjIBKbXshs3sfhw4clKChINm/e7NPz9O/fXwoXLmzZYytWrCidOnWK9OtPnTpVkiVLZtkYAQAAAMB2weaJEyekY8eOkjVrVgkNDZVnnnlGatasKcuXL3/s51yyZIkJGvW53aVPn14yZ8583wBTX09f+/jx45I/f34JJHPnzpVBgwb5exgx2qyZM6R6leeleJEC0qRRA9m2dau/h4QoYP7si7mzN+bPHlo1KCfrvg2Xk78PM5cV07rKi2XzmvuSJ0kgI3o2kC3z+si51SNk7+KBMrxHfUmSKMzfw8YjcPwhkAVEsKmBXrFixeSXX36RYcOGybZt20ygWKlSJWnfvv1jPefdu3elTJkyEjduXFmxYoXr9l27dsn169fl/Pnz5nWdfv31VxPkli1bVuLEiSPp0qUz3xtIUqRIIYkTJ/b3MGKsJT8tlk8+Hipt2rWXWbPnSa5cueXtNi3l7Nmz/h4aIoH5sy/mzt6YP/s4evKC9Bm9QMo0+VjKNhkmK9btldkjW0uerOkkfeqk5hI+cp4Ua/CBtOr3tVQpk1cm9Gvi72HjITj+AkuQny+BKCCCzXbt2pms4rp166RevXqSM2dOyZcvn3Tp0kXWrFljHjNixAgpUKCAJEyY0GQe9XuuXLniVTK6cOFCyZs3rwkcz507J8WLF/cINvXrcuXKmaAy4u2lSpWSsLAwrzJavc+Z9Xz22WclQYIEJpDds2ePx8/x4YcfStq0aU1A2LJlS7lx44bH/fo8JUqUMD+DjlXH8Pfff3s8Zvr06SbrmjRpUmnUqJFcvnz5gWW0N2/elG7duslTTz1lnrNkyZIeP9P9PGqMsdn0aVOkbv1XpXadepIte3Z5v98A89/D/Llz/D00RALzZ1/Mnb0xf/ax+LftsvSPnXLgyGnZf+SU9B/7g1y5dlNKFMwiOw8cl8bdJpvHHPr3jKxcv1f6j/lBapTPL3HiBMTHRdwHxx8Cnd//emhAqFlMzWBqwBSRc81hcHCwjBo1Snbs2CHTpk0zWdAePXp4PPbatWvy0UcfyeTJk83j0qRJY7KjmrV00q81aKtQoYLH7Rqk6WMfpnfv3jJ8+HDZsGGDyXq2aNHCdd93331n1j9+8MEH5n4t1R03bpzr/jt37kjt2rXN627dulVWr14trVu3NkGs04EDB2T+/PmyaNEic1m5cqUJDh+kQ4cO5nlmzZplnrNBgwZSrVo12bdv330f/6gxxma3b92SXTt3SKnSZVy36X9zpUqVka1bNvl1bHg05s++mDt7Y/7sKzg4SBpULSYJ44fI2q2H7vuYJInD5NLVG3L37r0nPj48Gsdf4AkOCvLrJRD5vU50//794nA4JHfu3A99nHtGTzN/gwcPlrZt23oES7dv3zbXCxUq5LpNA0gNrnQNpgZXGsB1797dBH/jx483jzl48KAcOXLkkcHmkCFDTLCoevXqJS+99JLJDOoZpE8//dRkCvWidHzLli1zZQ4vXbokFy9elJdfflmyZctmbsuTJ4/H89+7d89kaJ2lsk2bNjXZVH3diHS8U6ZMMf9myJDB3KZZTg3c9Xb9mSN61Bhjs/MXzpvS65QpU3rcrtcPHTrot3Ehcpg/+2Lu7I35s5982TOYtZphIXHlyvWb0rDrJNl90LO3hUqZLKGEt6ouX85Z5Zdx4tE4/mAHfs9saqAZGRoUvfDCC6ZkVIMxDcS0Hl2zmU4hISFSsGBBj+/Tcle9XTOXO3fuNOs1ixYtasphT58+LYcOHTL3xY8f35TRPoz7c2vgqk6dOuVaC6plrO5Kly7tsd7yjTfekKpVq5rGR5999pkJgN1pEO2+JlNfw/n8Eem6Vv0DoyXHiRIlcl00mNYM6f08aoz3o6W6Gii7X/Q2AABgP3sPn5SSjYZK+WafyKTZf8ikgU0ld9Z0Ho9JnDBM5o16W3YdPC6DJ/7ot7ECsD+/B5s5cuQwpaS7d+9+4GN0DaVmBDXYmzNnjmzcuFHGjh1r7rt165brcRowupelKl1fqesktWRWL7peUxsAxYsXzwSiztt1/aQGpQ+j3+PkfB3NRkaWZhy17FVf99tvvzWBonNNasTnd77Gg55f16vqz6G/C11b6rxoQKmBrFWGDh1q1o+6X4Z9NFRimuTJkpvfZ8QF9Xo9VapUfhsXIof5sy/mzt6YP/u5feeuHPznjGza9Y/0Hb1Qtu09Ku0bV3TdnyhBqCwc204uX7shDbtMkjt3KKENVBx/gYcGQQEYbGrGT7N9GjxevXrV6/4LFy6YgEqDLl0vqdlHDdKOHTsW6dfQ8ljNXupF12s6lS9f3tym2cBHldA+ipbErl271uM290DSqUiRIhIeHi6rVq0yW6vMnDnzsV5Pn0czm5r5zJ49u8dFO+n6MkZ3OlYt/3W/dO8ZLjFNvJAQyZM3n6xds9p1m/43t3btailYqIhfx4ZHY/7si7mzN+bP/nSdV2hIXFdGc9H4DnLr9l2p32mi3Lx1x9/Dw0Nw/MEO/B5sKg00NXDSDKRmLrXBjWbotCGQlnlqAKXrMUePHm3WV2rH1gkTJkT6+TWQ1OdcunSpa82l0q+1Ic8///zjc7D57rvvypdffmmyl3v37pV+/fqZJkVOWq6rgZtmNrUD7f/+9z8zpojrNiNLA+4mTZpIs2bNzP6b+vzazVczkT/++ONjjfF+tKtvkiRJPC56W0zUtPmbMvf772Th/Hly8MABGTywvym7rl2nrr+Hhkhg/uyLubM35s8+BnZ8RcoWzSYZ06cwazf1evlnc8isxRv+CzTHtZcEYSHSdsAMSZIwTNKmTGwu2kwIgYnjL8CQ2gy8BkEqa9as8tdff5lGOF27djVrGVOnTm323tQmPtrwR7c+0U6zGrBpRlKDKg20IkMDVg2QdH2oPqeTrl/UIFbXOuoWKb5o2LChWSupHXK14Y5u4fL222+bANdZzqulwtpJV8sbdD2mduBt06bNY7+mBo3a5Ed/Z0ePHjUlE5r51ZLjxxljbFeteg05f+6cjBszSs6cOS25cueRcRMnS0pKUWyB+bMv5s7emD/7SJ0ikXwxqJmkS5VELl65Idv3HZWa7cbJL2t3y3PFcpgtUNTOH/p7fF+uGn3lyPFzfho1HobjD4EuyBHZDj3A/3eDqhoAQCyUvHgHfw8Bj+n8+jH+HgJ8EBYQ6bFHW3Pggl9fv1S2/7aMDCQ2mToAAAAACFxBgVrLGtvXbAIAAAAAYhYymwAAAADgowg7MILMJgAAAAAgOhBsAgAAAAAsRxktAAAAAPiIKlpvZDYBAAAAAJYjswkAAAAAviK16YXMJgAAAADAcgSbAAAAAADLUUYLAAAAAD4Koo7WC5lNAAAAAIDlyGwCAAAAgI+CSGx6IbMJAAAAALAcmU0AAAAA8BGJTW9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPAVdbReyGwCAAAAACxHZhMAAAAAfBREatMLmU0AAAAAgOUINgEAAAAAlqOMFgAAAAB8FEQVrRcymwAAAAAAy5HZBAAAAAAfkdj0RmYTAAAAAGA5gk0AAAAAgOUoowUAAAAAX1FH64XMJgAAAADAcmQ2AQAAAMBHQaQ2vZDZBAAAAABYjmATAAAAAGA5ymgBAAAAwEdBVNF6IbMJAAAAALAcmU0AAAAA8BGJTW9kNgEAAAAAliPYBAAAAABYjjJaAAAAAPAVdbReyGwCAAAAACxHZhMAAAAAfBREatMLmU0AAAAAgOUINgEAAAAAlqOMFgAAAAB8FEQVrRcymwAAAAAAy5HZBAAAAAAfkdj0RmYTAAAAAGA5gk0AAAAAgOUoowUAAAAAX1FH6yXI4XA4vG8GHuzGHX+PAAAAIPKSVxnk7yHAB9d/7SN2sOv4Vb++fp70CSXQkNkEAAAAAB8Fkdr0wppNAAAAAIhF+vfvL0FBQR6X3LlzW/46ZDYBAAAAIJbJly+fLFu2zHU9blzrQ0OCTQAAAADwUZDNqmjjxo0r6dKli9bXoIwWAAAAAGzu5s2bcunSJY+L3vYg+/btkwwZMkjWrFmlSZMmcuTIEcvHRLAJAAAAAD4K8vNl6NChkjRpUo+L3nY/JUuWlKlTp8qSJUtk/PjxcujQIXnuuefk8uXL1v5O2PoEUcXWJwAAwE7Y+sTe7LL1yd4T1/z6+pmSx/HKZIaGhprLo1y4cEEyZcokI0aMkJYtW1o2JtZsAgAAAIDNhUYysLyfZMmSSc6cOWX//v2WjokyWgAAAACwex2tD65cuSIHDhyQ9OnTi5UINgEAAAAgFunWrZusXLlSDh8+LKtWrZI6depInDhxpHHjxpa+DmW0AAAAAOCjIF/Ti0/Qv//+awLLs2fPSurUqaVcuXKyZs0a87WVCDYBAAAAIBaZNWvWE3kdymgBAAAAAJYjswkAAAAAPgqyTxXtE0NmEwAAAABgOTKbAAAAAOAjEpveyGwCAAAAACxHsAkAAAAAsBxltAAAAADgK+povZDZBAAAAABYjswmAAAAAPgoiNSmFzKbAAAAAADLEWwCAAAAACxHGS0AAAAA+CiIKlovZDYBAAAAAJYjswkAAAAAPiKx6Y3MJgAAAADAcgSbAAAAAADLUUYLAAAAAL6ijtYLmU0AAAAAgOXIbAIAAACAj4JIbXohswkAAAAAsBzBJgAAAADAcpTRAgAAAICPgqii9UJmEwAAAABgOTKbAAAAAOAjEpveyGwCAAAAACxHsAkAAAAAsBxltAAAAADgIxoEeSOzCQAAAACwHJlNAAAAAPAZqc2IyGwCAAAAACxHsAkAAAAAsBxltAAAAADgIxoEeSOzCQAAAACwHMGmDU2dOlWSJUvm72EAAAAA+P+C/HwJRASbfvTPP/9IixYtJEOGDBISEiKZMmWSd999V86ePet6TObMmeXTTz/16zhjk1kzZ0j1Ks9L8SIFpEmjBrJt61Z/DwlRwPzZF3Nnb8yfvTF/9tDqlWKybnJrObmoh7msGPOmvFgim+v+0HhxZOS71eTf+V3l9OKe8s2A+pImeUK/jhkg2PSTgwcPyrPPPiv79u2Tb775Rvbv3y8TJkyQ5cuXS+nSpeXcuXNPfEy3b9+W2GzJT4vlk4+HSpt27WXW7HmSK1duebtNS4/gH4GL+bMv5s7emD97Y/7s4+jpS9Jn0i9Sps1kKdt2sqzYdFhmD24oeTKnNvd/3P5Feal0TmkyYI682GmapE+ZWGYNbODvYSOWI9j0k/bt25ts5v/+9z+pUKGCZMyYUapXry7Lli2To0ePSu/evaVixYry999/S+fOnSUoKMhc3C1dulTy5MkjiRIlkmrVqsnx48c97p88ebK5PywsTHLnzi3jxo1z3Xf48GHzfN9++615fX3MjBkzntjPH4imT5sideu/KrXr1JNs2bPL+/0GmN/L/Llz/D00RALzZ1/Mnb0xf/bG/NnH4tX7ZOna/XLg6DnZ/+856f/Fr3Ll+i0pkfcpSZIwVN6oUUR6jvtZVm46LJv2npDWHy2U0vmfkRJ5nvL30GMN/ajuz0sgItj0A81aaqDYrl07iR8/vsd96dKlkyZNmpggcM6cOfL000/LwIEDTSDpHkxeu3ZNPvnkE5k+fbr89ttvcuTIEenWrZvrfg0c+/btK0OGDJFdu3bJBx98IH369JFp06Z5vF6vXr1M6a4+pmrVqhJb3b51S3bt3CGlSpdx3RYcHCylSpWRrVs2+XVseDTmz76YO3tj/uyN+bOv4OAgaVApnyQMiydrd/wrRXKml5B4ceSXjQddj9n7z1k5cuKClMz3tF/HitiNrU/8QEtnHQ6HyTrej95+/vx5uXv3rsSJE0cSJ05sgtCIJa9adpst23+1+h06dDBBqVO/fv1k+PDhUrduXXM9S5YssnPnTpk4caI0b97c9bhOnTq5HhObnb/w3+87ZcqUHrfr9UOH/u8PNwIT82dfzJ29MX/2xvzZT74saWTF2DclLCSuyWo27Dtbdv99RgplTyc3b92Ri1dvejz+1PmrkjZFIr+NN7YJCtg2Pf5DsOlHGnA+rgQJErgCTZU+fXo5deqU+frq1aty4MABadmypbRq1cr1mDt37kjSpEk9nkfXjT7MzZs3zcVj3HFCJTQ09LHHDgAAgKjb+88ZKfnW55I0UajUKZ9XJvV6RV7s9JW/hwU8EGW0fpA9e3azXlJLV+9Hb0+ePLmkTv3fgu/7iRcvnsd1fT5n8HrlyhXz76RJk2Tz5s2uy/bt22XNmjUe35cw4cO7lA0dOtQEqO6XYR8NlZgmebLkJoscsSGCXk+VKpXfxoXIYf7si7mzN+bP3pg/+7l9554cPHberMnsO/kX2XbgpLSvV0JOnLsioSFxJWlCz2SAdqM9ee6/z4V4Atj7xAvBph9oeUqVKlVMw57r16973HfixAmz3rJhw4YmgNQmQlriEhVp06Y126lox1sNbN0vWk4bFeHh4XLx4kWPS/ee4RLTxAsJkTx588naNatdt927d0/Wrl0tBQsV8evY8GjMn30xd/bG/Nkb82d/wUFBEhovrmzae1xu3b4rlYr93+e8HM+klIzpkpk1nYC/UEbrJ2PGjJEyZcqYpjyDBw82QeCOHTuke/fu8tRTT5nGPs59NrUBUKNGjUzpamTPNA4YMEDeeecdk4nUTrVaCrthwwazFrRLly6RHqe+ZsSS2Rt3JEZq2vxN6fNeT8mXL7/kL1BQvp4+zZwMqF2HNa12wPzZF3Nnb8yfvTF/9jHwredl6br98s/Ji5I4Qag0fCG/lC+cWWr2mCGXrt6UqYs3yUdvV5Fzl67L5Ws3ZUTHarJm+z+ybtdRfw8dsRjBpp/kyJHDBH/ayOfVV181HWq1CVDt2rXNbSlSpDCP06Y/bdq0MeszNWCM7DrPt956y6zrHDZsmAlgtVy2QIECpiEQ7q9a9Rpy/tw5GTdmlJw5c1py5c4j4yZOlpSUEtkC82dfzJ29MX/2xvzZR+rkCeSL8FqSLkUi0who+8GTJtD8ZeMhc3+Psf+Tew6HfDOggYTGiyPL1h+Udz9d7O9hxyoBWsnqV0EOX7rUIFaKqZlNAAAQMyWvMsjfQ4APrv/aR+zg5KXbfn39tEk8e7oEAjKbAAAAAOCjIFKbXmgQBAAAAACwHMEmAAAAAMBylNECAAAAgI+CaBHkhcwmAAAAAMByZDYBAAAAwFckNr2Q2QQAAAAAWI5gEwAAAABgOcpoAQAAAMBHVNF6I7MJAAAAALAcmU0AAAAA8FEQqU0vZDYBAAAAAJYj2AQAAAAAWI4yWgAAAADwURAtgryQ2QQAAAAAWI7MJgAAAAD4iAZB3shsAgAAAAAsR7AJAAAAALAcwSYAAAAAwHIEmwAAAAAAy9EgCAAAAAB8RIMgb2Q2AQAAAACWI9gEAAAAAFiOMloAAAAA8FGQUEcbEZlNAAAAAIDlyGwCAAAAgI9oEOSNzCYAAAAAwHIEmwAAAAAAy1FGCwAAAAA+oorWG5lNAAAAAIDlyGwCAAAAgK9IbXohswkAAAAAsBzBJgAAAADAcpTRAgAAAICPgqij9UJmEwAAAABgOTKbAAAAAOCjIBKbXshsAgAAAAAsR7AJAAAAALAcZbQAAAAA4COqaL2R2QQAAAAAWI7MJgAAAAD4itSmFzKbAAAAAADLEWwCAAAAACxHsAkAAAAAPgry8/8ex9ixYyVz5swSFhYmJUuWlHXr1omVCDYBAAAAIJb59ttvpUuXLtKvXz/566+/pFChQlK1alU5deqUZa9BsAkAAAAAPgoK8u8lqkaMGCGtWrWSN998U/LmzSsTJkyQBAkSyJdffilWIdgEAAAAgFjk1q1bsnHjRqlcubLrtuDgYHN99erVlr0OW58AAAAAgM3dvHnTXNyFhoaaS0RnzpyRu3fvStq0aT1u1+u7d++2bEwEm4iysBj8X40eoEOHDpXw8PD7HpgIbMyfvTF/9sb82VtMn7/rv/aRmCqmz52d+Pszcv/BQ2XAgAEet+l6zP79+/ttTEEOh8Pht1cHAsylS5ckadKkcvHiRUmSJIm/h4MoYv7sjfmzN+bP3pg/+2Lu8DiZTS2j1fWZ33//vdSuXdt1e/PmzeXChQuyYMECsQJrNgEAAADA5kJDQ80JB/fLg7LdISEhUqxYMVm+fLnrtnv37pnrpUuXtmxMMbggEgAAAABwP7rtiWYyn332WSlRooR8+umncvXqVdOd1ioEmwAAAAAQyzRs2FBOnz4tffv2lRMnTkjhwoVlyZIlXk2DfEGwCbjRUgNdSM0Ce3ti/uyN+bM35s/emD/7Yu7giw4dOphLdKFBEAAAAADAcjQIAgAAAABYjmATAAAAAGA5gk0AAAAAgOUINgEAAOA3urcfgJiJYBMAEONt375drl275u9hAHDz1Vdfye7duyU4OJiAE4ihCDaBAOLeHJpG0YA15s6dKy+++KJ8//33cv36dX8PB27uF2DcvXvXL2PBk3XgwAEZO3asvPHGG7J//34Czmjm/EyxYcMG2bVrl7+Hg1iEYBMIoDeBy5cvm3/1DTcoKIg3XsACdevWlVKlSsmIESNkzpw5BJwBRAMMDToOHTpkrs+bN0/efvttAs5YIFu2bPL+++9L0qRJpXnz5rJv3z4Czmiknyl++uknKVeunBw9elTu3Lnj7yEhliDYBALkTWDRokXy0ksvSdWqVaV3795y5coV3nifoNu3b7t+1//884+cPHlSTp8+ba4zB/bl/ECl2c0cOXLIhx9+SMAZID755BPzobdNmzbywgsvyOjRo6VevXpSsWJFiRMnjr+Hh2jkPJlQs2ZNM/+pUqWSVq1ayd9//837XjQ5d+6cbN68WQYPHiyVK1eWuHHj+ntIiCUINoEAoGUt9evXl/Lly0vq1Kll5cqVUrt2bbl06RJvvNFs1KhRsn79eokXL575XWtQovOgl5dffll+++035sDG9AOV84Pt7NmzJU+ePAScAWDQoEHSo0cPuXnzpixbtswcY126dJGPPvpIXnvtNX8PD9FM51vp3C9cuFCOHz9u/tY2a9aMktposHPnTkmfPr1MmjRJ0qRJ4+/hIJYh2AT8bNu2bbJjxw4ZOHCgDBkyRKZNmyY9e/aUq1evSq1atVwBJ2Vl1tPM5Q8//CA1atQw86C/87Zt20r37t3NJXfu3FKlShXXh2E+/NiTe5ZMA85cuXIRcPrRqVOnzDx8+eWXkjVrVlm+fLnJaOmH4ZkzZ5pgAzFzqYjzb6hW8/zyyy9mLXXRokVl2LBh5v3vxo0brOGMht973rx5TXn64cOHzbHG7xVPUpCDLiSA32gJWZ06dWTPnj2mdFbP9DtL/3RtxQcffCAJEyY0jU2SJUvm7+HGSBpkalmRnlXX37euG9J/lZ5t79+/v3zxxRdmPjTw1Ddp51l5BC59a9MPtLoWUMvH9PjRYCZBggTmfi3X1OOuV69e5uv48eP7e8ixam50Ha0GFnpCTctnhw8fbspny5QpY/7+aYVB9uzZPcrctfoA9qTlm4ULFzZf6/zqCSA9oafHp570cdI1u/r3OFGiRKZTbaZMmfib68Pfv4g6dOggkydPllmzZpnqKeCJ0GATwJN39uxZx7179xzjxo1z5MmTx1GuXDlz3enOnTuORYsWOXLnzu146aWXPO6D7+7evev6etu2bY4GDRo4QkNDHbVr1/Z43LFjxxytW7d2hIWFmflA4HMeK3PnznVkzpzZkTNnTkfKlCkdPXv2dGzatMn1uLp16zoKFSrkmDRpkuP69et+HHHsm5/ly5c78ufP7wgKCnJ88sknrvtOnDjhKFKkiJmXffv2mduGDRvmaNu2LX8DbWrFihVmnidMmOBxe7du3RyFCxd23Lhxw+P2vn37mscXKFDA9d8AIs95nPzxxx+ODz/80BEeHu74+uuvXffrsRQ/fnzHggUL/DhKxCYEm4Af6Ade/aCrgYx+yNUPu/rBq3Hjxo5bt255BJw//fST49ChQ34db0x+Q3YGnRpw6u9fg8qNGzd6POb48ePmvlSpUjmuXr3Kh14bWLp0qSNZsmSOUaNGmevDhw93JE2a1NGsWTPH+vXrXY+rXLmyo3Tp0o6LFy/6cbSxz6+//uoICQkxJwJeffVVxz///OO67+TJk45nn33WHG96ok2Pyb/++suv48Xj07nt1auXI3ny5I7PP//cdftXX31l3vd+/PFHj4Bz4cKF5pjUY5X3vsczZ84cR5IkSRxNmzZ11KlTx5y0rlevnuv+du3amfu/++47v44TsQPBJuAHa9asMR98x4wZY65fuXLFMXHiREexYsVMUHP79m1/DzFGcwaL//vf/xwDBgxwHD582Fzfvn27yWymTZvWK+DUjIueHEDgO3/+vKNhw4aOPn36uD7sZsuWzVG+fHnzb6NGjVzz67wfT9aWLVscS5YsccycOdPx3HPPmQ/E//77r+t+Pe40QNHLjh07/DpW+E7/dr733nuOxIkTe2Q4K1asaDKYGmBeunTJ3KYVCJp9u3Dhgh9HbF/79+93ZM2a1VRNqd27d5tAv0OHDh6Pa9KkiSNDhgyOy5cv+2mkiC0INoEnwBmw6IdgZ+Zy7NixjkSJEjlWrVplrmvGTAPOkiVLmrP5BJzROxfff/+9Cfj1w+zevXtd92vAqR9806VL5yq5JJMZ+Jxz5Dy+NFuyZ88eU66u2ZOWLVua2z/++GNzRl8rC9atW+fXMcfG+Tl69KgJPNwD/C+//NIVcOr97rS6AzGDnkxwBpz6/uf87+KFF14wAWf27Nkdzz//vMlk699hPJ7ff//d/D6Vnkh95plnHG3atHHdr+W1Tlq1A0Q3VlwDT4Au1P/111/lueeeMxvLa4fZdu3amQX6n3/+uZw4ccI0LmnatKlp+69dUXWfR0TPXKxbt05at24tn332mQwdOtTsv6j0954vXz4ZOXKklC1bVkqUKCFbt269b6MFBOa8fvrpp6YBiW5dkzNnTtNcK2XKlKb7rNKthZ566inThfbpp5/297BjVbOSBQsWmMZAuqem7vPXp08fc/+bb74pLVq0kLNnz0qnTp3k33//dX0v+23aV8T+k3rc6fy2b9/edFwfO3as+e9Cu31rI7bmzZtLpUqVTDMh/TuMx6OfJdKlS2f+HupnjurVq5vftdLf7TfffCO7d+821/VxQHRjR1cgmv3/CgLTeXbv3r2mtf/06dPNRTsv6h9+7Yiqf/S1I6YGQbrXGN1no492QNTOiPrh5tq1a7Jo0SKz5czly5fNm7PuAThgwADTCTgsLMzfw0UkaWCpXUxbtmwpKVKkMLddvHjRnNzRudWN47UDrW5vwzH25GhAsXTpUmncuLHpOqsBxZIlS8y+mnpSp1q1ama7C32cnowLDw+XqVOnEmjGgBMM2uVb95HetWuXNGnSRAoVKiR9+/Y19+k867964lVPQugFkQ/i9Xd3v66zyZMnN7/vUqVKSatWrWTixImu+/R9Tvfc1JNuwJPC1idANHG+CbhvwaAfrjTA1D0z9YOxbrmg2TXdA0v3HEP0cX9T1v393nnnHdNiX/f70zdnDUQ0A6b7bn733XcmGNUN50NDQ/09dDxiTm/duiUhISHmtgIFCphMtQad6ttvvzUZtGzZspnHrly5UtavX2+OOTw5ms3S4F73UtR9/pzZzQkTJng8bsaMGVKuXDmz5QXsTY9BzVrr+5xuI6UXzVjqVlK6HZFm23T+Nfh89913/T1c29CqDD0x7fy798cff8jatWvNydGaNWuaDLJmi3X/aD3x9vrrr5vH67Glv/vff//d/J0EnphoL9QFYrG1a9c6Xn75ZdNcxrmOTNdp6joKXTfRr18/R758+Uyb98GDB/t7uDHSg9Zb6nYm2jDm7bffdq3d03nS+dAGTrAHbfKkrf2da591vZJum+He9VK/1jVLr7/+OmvB/EDX0RYtWtQ0htGuv0899ZQ5/pzHpjYy+fnnn/09TFhI10vrGkzttK7OnDljtpbq3bu36zGnT592vPPOO2ZNofYzYG38o2kHX+0n4PxMod1k9TOFbiGTI0cO0xho165d5r7Zs2eb3602AdLt1bTDs/vWT8CTQmYTiAa6CbVzjZKuCTx8+LApy9QyMt2oWrOYU6ZMMVkzXVehm1trWW2uXLn8PfQYmflavXq1/Pzzz2ZjcM16NWzY0Nx/+vRpj3IizYDp2Xg9K5w+fXo/jhyRcePGDWnUqJEsXLjQnKnXUkzNpPTq1ctkpbUc2n1dplYUUJrpH1pFoOvE9G9frVq1TFZLj0edw7fffttknnUdX7x48fw9VESRZszy589vSmSdtHrgrbfeki1btsi+fftMFrtq1aqmR4HatGmTefyZM2fM32jKOiNHy5L179uVK1dk8eLFMmrUKJMt1uylrsfs16+f/Pnnn7JmzRrzeUKX75w/f95kQPV3rFU8wJNGgyDAQs5zN/ohSt9AtQGQlrfoB2BdK+EsJ9Iyl+XLl5vSlgoVKphgiEDTejoHGjy+/PLLZt2Q/p61ZGvgwIHmfucHHP2w1LFjRxk3bpx8/fXXBJoBzP38qK6n1bWXegxpgxn94KUftvQDlZapa1MudwSaT+ZEm9IySQ0knHLnzm0+KGvw36NHD/M38vbt2+aEgM6Tnogj0LTfsagBjq4JjBjE6FppbVRz7NgxqVKlirz44ouukulVq1aZk61HjhyRNGnSEGhGgTY+++STTyRJkiRm7fPGjRtN0K5/24oVK2YapOlSnZIlS5r16fpZQ08EaLM0Ak34zRPLoQIxnLMESMv5PvroI8eHH35otteIWO6nbd21bFbLyiJ+L6ylc/H000+79nXTEiLdbyxu3LiObt26uR43ZMgQR9WqVSmxtNG8zpo1y3Xs6JYZb731luPmzZtmj76OHTuaYyxOnDiOzZs3+3u4Md6MGTM89qCdO3euKUfX0j33ZQSjR492ZMmSxVGhQgXHq6++auYtZcqUjr/++suPo4evtATWuXeqc/9aPRZ1rvU4fPfddz0e37VrV/PfgJbR4uHu3r17388I+ruuXr26eS9z7kPrfOy+ffscr7zyivndHzhwwA+jBjwRbAIWmjNnjlk/Ua1aNUfu3LnNeokGDRq47tc34D///NN8EEuYMKHHJuaw3vjx482aTPX33387MmfO7GjevLlj6NCh5k160KBBrseygbg96MbvnTt3Nh+kdJNynVe9Tdcj6fow/VCmH8QaN27sWh+N6KG/63Pnzpl9S8uUKWPW5WngmCpVKkf//v3NWsy8efOay86dO833LFiwwKxVr127tjn+dMN52JMzANJ/db/GIkWKOOrXr+9Yv369uX358uUm4KxVq5Zj//79Zj119+7dzX8vW7du9fPo7UP/xi1dutS1ZvO1114zX2vfB92XO1u2bI5Tp055zIkeV3pCh+MLgYA1m4CPJWNaDqa026yW82mJWIcOHcw6Ce18qdssPP/882bLEyctpdUST/a4ip41mrqtgnbq0y0VtMyoaNGi5ussWbKYTrQHDhwwpUa6ZlPny7kHI+xDSy/12HrmmWfMXOqaPy1Z147P2bNnN4/RMk7tMozo+9unnTG1VFJL1bWDrK6/dK4dc+5dq6V/usXQnDlz6AIcg2k/gvHjx5t18d26dZOCBQvKjz/+aDrN6n8HSZMmNR2JtZxWu33j0XSduXaY1X239T3so48+Muud27RpY+7XpSH6HqZl6/o3UcuSne+DWqZOaToCgr+jXcCORo0a5SpPcZauaAfTTJkyOQ4dOuSRydRSWj27q2W07o9H9NDMsZ45nz59uus27c5XsGBBV4nX0aNHHQ0bNnRMnDjRlBwhcDnP1OvcTZkyxcyZs9z5n3/+MSXQpUuXdiRIkMAcZ2PHjvX6XljL+TdMy9J1OcC2bdsce/fuNZUDmnFu2bKlx+OvXLliHqfHICWzMaO7sPPYun79usd9X3/9taNYsWKOpk2burKX+ngtfdf3zLNnz/plzHaXP39+c2xpCfL93vOee+45c3xphhkINDQIAqJIGx/ohuO6GbnuF+fMbGqTAz17q91lnbQDnD5OzzBq5lM5Hw/rOAs0tOGEdrvs3Lmz6c7n3rDp4MGDsmLFCpORGTNmjJw4cULq16/vyoIhMOkZes2I6dn9yZMnm6+186w2ddJmM127djVVA9qVVrs+a9dTzbbdb7NzWJfR1OylNiHRxi/agESzWdrxWbNZ+jfwn3/+MY/XedD9/7Q50OXLl81+m1p1APtxNtzSbJkeWz/99JP5G9q0aVMZOXKkua9Jkybm7+/OnTtl2LBhpjGbPr506dKSNWtWSZEihZ9/Cns02NK/YdpRe+/evSZrmShRInNsaZfZRYsWuR6ntLJDM5537tyROnXqmPsoWkRA8Xe0C9jRwYMHHS+88ILZL865JkybHbz00ktmjaZzzYq6c+eOo1y5ch77/sE398sOa0ZZ9xNLkSKFx15uegb+6tWrjvfff9+s4cuZM6d5DBkWe9DsWerUqU1GU2l2RM/w9+nTx+ux2jRI14Yheo87XQemx9IHH3zgus+Z6XJmOCtVquRqDOS8T49D/dsJ+9Hsme7v6GysppU88eLFc7Rt29bx4osvmqyaZjPdM5ylSpUyTaB0DTUif3zp+ua6deuabKb2FtDPGu3atTPHkR5XWsnxww8/eL0P6vdxfCEQEWwCUeD+x10/cGlHPe24qAv4lW5Mrs1/9I1CS/60E6aWvWjHRd4ErJ0DDS61nFk7HV67ds3cpgF9smTJHJUrVzYfet1pAwVtUKENFtxLnRHYFi5caBqMKD2GtLuwfsB1cjbGwJM57vRvmh5jGvBrwOE8oebOPeA8efKkuY2SZnvTEwcDBw40AVCPHj3M+9vIkSNdzdUmT57syJUrl6t5jdLb9L8BXbaAh3MeH1p6nDRpUkf79u3N70+X4ejfPz3e3njjDdNUUINPDTj1b6PSDtzNmjXz808APBjBJvAYbwj6R75mzZrmjVTfBHStmDOYXLZsmaNevXomwMyRI4fpSksWzdoPvPqGrBnK1q1bm4tmTJy++OILcwZeux4SVNqffuDSTrO67lbXROt8O/87+Omnn8yWJ86tFxD9gWb8+PHNCR79MKzbOOnfO/fHuAec2bNnNx1KOSEQM973dB51jXThwoUdGTNmdHz55Zeux2hHaP3bqwGne4bz4sWLfhmzHenvV4+XXr16ed0+ZswYR0hIiDnubt++7ahSpYrp8qxdoHU7L10TCwQqgk0gilauXGnKh3TvRm1aMnv2bEeJEiVMSa0zuNE3WN13Tj8g63YAsM6ePXtMIK9vyNp4wknfgN23PNH50DPwbH1hbxrglC9f3mTTdNsa98CmS5cupoqAbWuinzbSCg4ONuXoSv+uaSMgDTh1i4v7ZS+djbk4Bu3NfV41w6kBp5a2O49Hp8uXL5uMZ5o0aRytWrXy+l48nJ6U1syxNtxyVgs4/9bp37jBgwebgFMrdPS6ZpZ1+yA9zoBARrAJRNHw4cNNmaY7/WOv2ZesWbM6jhw54rexxWT6oUWDS81kvf76644bN254PcY9u6IBp2bC9Eyws8wZgcv5oVQ/cC1atMjVvVlpKbp+uP3444/N2mgNXrR0TNfeOjvTInppOezUqVM9botMwOl+Qgj245zPtWvXunoR6LxrwKnvd3ocutMMp67XZO101GmgrseSU8RjSauntMRW94kG7IS2mMAjROzqdunSJdm+fbvH/blz55aOHTuajrPFihVzdWKEdbT7oXY11E6XuXLlktDQ0Ac+VudE92DUOdEOimFhYU90rHi8+Z03b56UK1dOunfvLlWrVpXWrVubjoyffPKJvPLKK64OtA0bNjSPXbZsmeTLl8/fQ4/xtJu27t+XPHly+f33311/E1OmTCkff/yx6fz80ksvmU7QOo/unTLZ58++nB2d9VjTfVQXLFhg9nvUeW/VqpW0bNnS3NarVy/X9yROnFhee+01s+8tosbZGV07bquI3bR1n2jt6KtzANgJwSYQgfODlG6m7PyDrx9qp0yZYq7Xrl3b9SFLW/g73xD0TaBGjRrmw7K2LYf183LmzBmzvYUGHMr9Q63SLRl03nr27Gk+IOu2GH/++af5oIzAPt7Onz9vgspx48bJ0qVLZcmSJfLNN9+YbRU04NRtT2bPni3Tp083W9foNjZFihTx9/BjxfxowLhlyxbzt0+3YnCnW1notgsacOr9Onds72Rvzr+r+t6m86nH4Icffmj+nqZNm9a11dfbb79t7vvxxx/NiT0nthx6PJkzZ5YkSZLIV199ZbZVizgf+jcyfvz45oQ2YCe8IwARrFy50vwbJ04cE0zeuHFDunXr5jpDr2cfK1SoYPYYGz58uLlNH6PXEyRIYLIvOXPm9OvPEJP8/3J/8wFGMyuayZo1a5YcO3bM9aHWPfu8a9cuE4hoUKqSJk3qt7Hj0XRe//e//8n7779vsiGaIXvmmWfM/o16kkePq2bNmpm95nQvxwYNGsizzz4r6dOn9/fQY838bNy40RxPgwYNMtmsiMGEBpx68k3nrnnz5nLt2jW/jRePT4OcHTt2mL+rGuDoibu5c+eaOW3RooXZN3rr1q2m8uCzzz4zexV36tRJatWqZfbTPHXqlL9/BFvTk6jjx483J9r69Olj5kI53+dGjBhh3veee+45P48UiCJ/1/ECgUTXpGh3WW0s4067782fP991XdesdOjQwSzm1zUU2iBI953TZiaIHvr737Bhg9nbL06cOGb93v2aL/Xt29dRtWpVuiDayHfffWeOO/ctgpzrb3V7De22qHvY0tX0ydM1str1UuenY8eO993qxEm7AmtjNNiPrrHUfTGLFy9umrCp69evO6pVq2Y6r+va6BYtWphtN7TDur73ORsE6XpeGuFZQ48tbT6o+2tqZ1/9neu+0bqljP4dpLM97IhgE3Bz9uxZx6effmqakYSHh7tu146KuoemcjamuXLlimnvP2LECLM9Q8R9HeE7Z4MEDeL1w67ukan0jVe78r333ntmI2tnk6ZOnTqZpjHazQ/2smDBAjOnuq3GzZs3Peb/jz/+MPtr6h5zeLJ0LubMmWOCEP076PSggBP2pY25NLjUoHPHjh2u7usa5OiJoAYNGpgTQ0o7oepJVucex7CWnmTTTtu6b3fZsmUd7dq1o+ssbCtI/y+q2VAgJrtw4YJZF9avXz9TMjZs2DDJmzevKW/R8lk8WVrC9++//5qmTL179za36Z+tNm3ayMyZM83XuiYzUaJE5uuvv/5aChcu7O9h4wGcJdEHDx40jS609FzLx3QdtJZH6xowLc374IMPTOm68/Faqk6jJ//QNejLly836/J0bbp+rbTMUpcbwN7c53H+/PkydepUsz7+yy+/NEtCjhw5Yo7V4sWLu45HXb+p63f1mE2YMKG/f4QYOy9aQutsusVaaNgVwSZwH7oQX4OWvn37ms562gFVu+xpF1Rdj6RvzPoGkC5dOhkyZIi/hxtj6QceDfB1HWaHDh1k1KhRpvGPc/2srvXTtWTa/bd06dImyMyQIYO/h40HcH5Q1XVg4eHh5roGmWratGnmg+33339vjrkuXbrIwIEDzToxPNn50RM8mzZtMl+XLVvWdNvWYF/X0Op6PV1Tq8eeIuCMOfP+888/m/e93bt3y/r166VMmTLy+eefm5OtTvrfhnZLHTt2rOlMXLBgQb+OPTbMS8SvAbsh2AQe4PTp0/Ltt9+azKYuytcGJnp298qVKybY0Q9Z2jgof/78/h5qjKUNmhYtWmQ6IWpHUu2IqfTrh219gsClH1C1a7M2lNFulpqd1k6mepxptkRpwPnqq6+aJhkDBgzw95Bj3YkAzWBqAybNWO3cudO1JY0z4NStLjQjrSfhEDPoFlEvvPCCfPrpp6bL8+rVq81/C5pN00ynngjSk379+/eXPXv2mJNDhQoV8vewAdgAwSZiPeeHLO38puWaWq5SuXJlE1BqcKlncQcPHizt27d3lXHC/yV8d+7ckbhx4/p7eIgkZxmYlsdqNlozJkePHjUZad1DU7czUZcvXzZVBFrOp5UEefLk8ffQY6T7ZUq0E3f9+vXNHOk+itphtESJEqZ8WU8A6EkCDTgXL15sTgDpbRkzZvTbzwDfOT8C9ujRQw4cOGACTCfdQ1M7EOt2G9qpVvd51OUM2n2YChIAkUWwiVjNfdNqzVLqh2E9m69BjJ7BT5Ysmclw6roULemrV6+eTJgwweN7YQ1K+GKOh60v0uNMTxRoFlPL9DSA0WNK51uz2IcOHZLWrVuTuX4C86N/25z7+el2Mpq10uNQs8l6IkDnR7NdepxplYduyVCxYkVTWaDl7LpOGjGDZqt1ftesWeOxNlrf9/S/Cy2l1ROvegIIAKKC1caI1fQDrmbK3nzzTfNmq2VCWt73119/mbIxLZ/Vzat1DZme+dUgRz+gOb8X1pfwaZZLgw89k677if3xxx/mw49mm50lzZptUQSagRvIaBAzevRo+eijj8xaMKennnpK/vzzT3MiQQPNiRMnmts1ePnhhx9M4yDOgUb//Gh5bJ06dUypsmYyVc2aNaVatWomu6wn1vRrbRKjwb+WtD///PPmb6CeCCDQjFkKFChgTgLpST09meBUrFgxKVWqlDkZwQkgAI/Fv81wAf+6dOmSaSmuezeqo0ePOjJmzOho3Lixo1ixYmafqxMnTri2RTl37pyfRxwzOLe0cLdixQpHqlSpHJ9//rnHnqfx48d3/Pjjj65935zbMPz9999PfNx4OOfemLpVzTPPPOMoXbq0I3PmzI4ECRI4vv76a3PfrVu3zNYKCRMmdGzdutVc1+0TdKuh9OnT097/CRx3umdismTJzNZBehxF3MZk7dq1jmeffdY1F/r4V1991dG9e3fXVkOwJ+d/A7o91OrVq81cO1WpUsVstaF7Gjv3Ke7Vq5ejTZs2jgsXLvhtzADsjTJaxEruJbC6NkxLM3U9oJaMadZMtzn57rvvpHHjxqZRhpZ2audZ+I4Svpg9r1u3bjXrMN955x2zfdC2bdukSZMmZh3mjz/+aI4jzU7rXOoxqCXruu5v8+bNZi2gNidB9Dl37pzUqlVLihYtKp999tl9S59/+ukneemll8xcagM0zX5qtcfs2bNNYyDYm5bD6rZeuvby1KlTpqTd2YirevXqpru3Ll3Q41IbBWlnWhrhAXhcdNdArAwy3Utga9eubf7V9WLaCEHLafV+3ZJBy/z0ay0rI9i0toRPS/M0ANHfuZbPagmfluq5l/BpiaWWXOq+p1rCpwHniy++SDlXANJ5PX78uCl3rlq1qgwdOtTcrnvz6Qkb3atP500/xGpzEW3IpZ1otWw2e/bsMm7cONOABNHrxIkTZp70GHMPMJ3/6t9InUP9u6jbWuiJIF1eoOXsBJr2f+/TfaQ1sNQTDTq/GkjqtlJ6u96mJxoWLlxoGgEpPfHKOk0AviDYRKx7s9UztdrmXbNj+uG2WbNm5n790Ktn8jNlymSu62M0wNT9xAhurPn96wdaDTJ0PWy7du2kTZs2Zg2fc22Q0u0UNJvZuXNnc12bNDVo0MDMi2agEbg0I63BpQaWv/zyizlBoEGnbneimbQ33njDHHeatdatTRo2bOjRjATRTzPIWlGg66Hvt1m83qZzpJkv/duoDZtefvllyZEjh1/HjajTAFL/fjrndenSpfLbb7+Zudeuw9oMTysJ9DFNmzY1j9GtT3TdvF4AwAoEm4g1nA1o9ENUlSpVTAA5cuRIc8Zet2HQM/16FleDHy0ZWrVqlQlMCTSt+/1rCV/btm3Nh9ghQ4a47nP/wHv27FlTtqzNKpR2Ata9TbXMlsxKYJ/I0SyYls4OHz7cdJ3Vffi0NFbLL/UDrp5o0A3j9X7NZGrGRJsHaaMnGm49GZkzZzaly/q3UP/m3a9rsO6rqMsLnF2fYT+6NY1mKbUBns63HqNa0q4nf/TEgXtzNT3xo1q0aGEqD+i4DsBKdKNFrLFv3z7p0qWL2TNT12PqOiR9M3W+6WoWUz+AabZFz/ZqeZF26EP0lfA5PaiET9fP6pl27ZZJoBm4nB9ItRRdv+7UqZMJJL/55hvztc53mjRppFKlSvL222+b7LWuw500aZL5IMwH2idHKwSSJEliuj0710wr9/YNut+iZqJp6WA/zjnTE3p6ElWPLw0g9RjTY0/3s9X5de5r6x5w6slWPcmg6zgVxyUAS/i7QxHwpGjXvaJFi5qvDx8+7Hj66acdbdu2dd2/YcMG19cRuzPCGjNmzHDEjRvX1RHR2b3U3dWrVx2LFi1yzJs3zzFixAjH3r17/TBSRJZzLrUDrXYPnjJlirmunS4bNWrkKFSokGP58uWu+b59+7ZfxwuH6egcGhrqaNq0qWPHjh0ex552Bc6UKZNjz549fh0jHt8///zjOHbsmPn6119/dRQpUsS85zk7eg8bNswcqyNHjrxvh3YAsBJltIixnCVAukZFM2fajEbXh61cudKc9dVui7oPoNq0aZM506t7aebJk4f9G6MJJXwxjx5jWvb877//yqBBg8y6TKV78+kxOGrUKJPd1Ay1ruG835zjydLKAW0Go41htIJDuwfr30Zdc7tmzRrTiCtnzpz+HiYeg3br1pJ1Pda++OILUzKrnb8bNWpkKnp03XvHjh3NY7XSR9/rnNeVvk8CgJV410eM/hCsTUq0o6yuA9QPU9evXzfX9Y1Y16Vo4KO+/vpr82FZS/0QfSjhi3nOnDljTt7UqVNHTp48aW7TBjNKg5h3333XrN1s3ry5OfED/9OAX5tzaadnXZ+uJ9u0+6ieaNM17Gw/Y1/aY0BPmmpHWT1ppz0I1q5dKxcvXjTHqG5roo/RAPOTTz4xx6dzjSYARAf22USMXh+oWTJdG/jee++Z27RRia7J1DdYfePVLnz6mClTppgPwqzRjH6a1XzttdfMGiHdZiZv3rzm9mvXrpn1tLodhmY1yazYg25Xo2s1tSGJZlW2bNniuj0kJMR8rd1op02bZo5D3c8WgUM7P1PJYV8Ruwmr/fv3m31u9f1Nm3Hp1kOatdZto3SrqXnz5pkMp67lnDx5stnPWE80AEB0INhEjPzwpO36NVhJnTq19O7d27zxOmlpkZb2aWZNM22a3dTbChcu7Ndxx6YPR9oYRkv4dH/F+5XwkVmxF60Y0K6Xmi3RYFK/jhhw6gdbtjkJPO4dR+k+ak9aDaLvedpczUmrR3R7KT3Jo0sWlDPg1OoSbd6lyxoAILoRbCJGnNXVAFMvzg+2SjMtmknRNWRaLpQiRQrXffqmq6W12uE0ZcqUkjx5cj/9BLGXdiQdNmyYOQuv64R070Xdlob9/AKXMxjRNZpaeqlfly1bVnLnzm2CyWXLlkn37t1N1sS55lZLauPFi+fvoQMx8ni8dOmSOcFz/vx58/dUO3jrmk2l73168k6rDdKmTWtuO3bsmNmiSI9ZPUadS0kAILoQbML2geaePXtMMKlndvVNtnPnzubMrfroo48kPDxcRowYIW+99ZYkSpTI38OGG0r47Bdoahm0ZjC1NE83hd+5c6cpyytXrpwr4NTyaD2RoycUAEQvfY/TfWv1hJ2e6NFjTxty6Yk8XU+twaW+F2oJrdLtp3TZQrZs2fw9dACxAA2CYOtAU8/YamblwoULJiOmG1aPHDnS9biePXtK//79pWvXrvLll1/KlStX/DpueHJfa8R5r8AScT400NROztpYRo+pDRs2mPVgWiGgpXmLFy82ZbJayjdw4EDzPUeOHPHT6IGYyX1/YmcjLj2R+vrrr5slCdWrV5fNmzdL8eLFTQWPrsXUSoStW7eax965c8ecKCLQBPCkUD8B2waa+uapZ3J1W4UhQ4aY+7RUSDOcWlKkZ3H1w2/fvn3N92iHPl1bpmsFNSMD/3NfH8ZascA7xnTLBGfXYM2O/Prrr2YdWKtWrcwHWV0LpqV6mqGuW7euKdmrWLGi2VZIA1AqCQBr6XF5+PBh01FWg0aVMWNG00ldq3y0skeb37Vo0cKsjdcy2dWrV5ttvkqWLEnZLIAnjjJa2JKWAel2Clq6p2V9TloypBkXLRHKkiWL+cCrJUZK//38889NaRFrNIGHB5paHtu6dWuznlZP3OhxphkSbfqj22VUqVLFHIMTJ040W2g414lpwKnHHQDraan6yy+/bE786BrNatWqmY7eV69eNdlMPQ71mFQLFiwwJ2X79etnrp86dcr0KODEHoAniTJa2JJmVfSNVcv0dC9NZ0Mg/UCsWRfNdOoHZj2zq+V9Skts9cwvgSZwf3ruUY+bHTt2mPL0ChUqmA+uumWQKlasmCnV27Vrl8lmahZF6RYLDRo0kG7dupk1YwCihzbB062GdGmIblui+9fOmjXLVOvotlF6slX/VbVq1ZI+ffqYRkB6TKdKlYpAE8ATR2YTtuLeml+bj+iasX379pkMy08//WTavFetWtXcr6VGuXLlkg8++MC8MUf8fgDezp07Zz6kFi1aVD777LP77uenx5qWymrWRLOc+oH2r7/+MkGpNicBYD3nMajVAxkyZDAnXfUEq27dpWWzr7zyiuljoJU9upd0unTpeM8D4HcU78NWnG+aemZX12fqek3dM1P3DNOmJRpoasZF32CTJk1qPjBr1iXi9wO4vxMnTpgydV2P6R5gOv/VY0ubANWuXVsKFixo1nJqpvOPP/4g0ASiuepAg8kaNWrIlClTTFbzhRdeMEGmVhUcPHjQNMvT41arErTElvc8AP5GGS1sw5mE1zdbfXPVsiAt6dMzuNoQQUuJdDN53UpDmyDodie6p5j7RtcAHk47WWpTIF37pR9u3btfKv3wql0wdU9Uzao0btzYZDW1ugBA9HDub6sVO4MGDTKBptI9bGvWrGlOwD7//POmcZBWHGhDPO08S/EaAH+jjBa2om+2//77r2zfvl169+7tul277WmGUwNQbQKkDUvef/99WbVqlRQpUsSvYwbsRI8ZzZZ8/fXXJrt5P7qn3/z5881aMADR78yZMyZbqVUE2lFd3++c+xQ7S2W127o2AdJgVPfC5QQQgEBAGS1s9War3Wadb7ZKMyx6ZlcznPpmO3bsWLP1gp7RXbt2LYEmEEWZMmWSJEmSyFdffWVKZPW6cl/7deDAAVOiznow4MnQY1KDSG2Ep/vdKg00nQGn0q7Rerxq4yAACBSU0cJ2b7b6Adj5ZquBpm7FoEqVKmW2amjatKkpI9LOmQCi5qmnnpLx48fL0qVLTeMf3QJFaVCpjUfee+89mTNnjmlIQqAJPLkutNWrVzf7Rl+6dMlUH7gHnAAQqCijha1omZCuy9QSoaxZs5qvlQac+mbs3IcsLCzMzyMF7EvXaeq2QVpBkD17dlM5oMeUdr9cs2aN6YZJ1QAQPZwVA7psZNOmTeZr3Yood+7c5v1t2bJl0r17d7PNkLOU3T3DCQCBhGATMebN1llSC8Aaur2Qbhy/f/9+SZw4sZQpU8Y0BsqRI4e/hwbE6Pc+bb6lJ1XTp09v9tDUCoN58+ZJuXLlXO+BvXr1Mh2g9TgFgEBFsImAw5stEDjImADR537rnnWZSP369c0e0a1atZINGzZIiRIlTHXB999/b7Y+0ffAxYsXmzWcelvGjBn99jMAwMMQbMLveLMF7HF80hAIsI5zH9vTp0+b7YaU9iTQPaP1WBswYIApXdeKAl2jqSd+vv32W1PGro3wbt68aSp6EiVK5O8fBQAeiGATfsWbLQAgtr73acWONrbTMnXtJqsVPbp8RPsQ5M+fX6pUqWK2MJk4caLZ0kv3v1X6Hvjiiy/6+8cAgEdi6xME5JutblKtb7aXL182e/1Vq1bN9WY7ffp0s3m1881WN7EGAMAO9ESqvvfpvtC6LKRdu3bSpk0b0wlaOTup6/IQPcHauXNncz1ZsmTSoEEDs72J9isAADsg2IRf8GYLAIiNtBT93Llz0rZtW7N39JAhQ7xOwqqzZ8+aLKfuG61mzZolV65cMZU/2qsAAOyAYBN+wZstACC2OnHihBw/ftxU7ri/5zn/1ROylStXltq1a0vBggXN8pJdu3bJH3/8wXsfAFsh2ITf8GYLAIiNNm/ebPoU6BpMPfnq/h6o9DbtR6BbDekJ2UOHDsnLL7/MtkMAbIdgE37Dmy0AIDbKnDmzxI0b1/Qo0BOu7u99TlOnTpX58+e79pIGADsi2ITf8GYLAIiNtO9AkiRJ5KuvvjJVO3o94vZCBw4ckKJFi7LlEABb8/50D/jhzda57Yly343H/c0WAICYQJvhjR8/XpYuXSp9+vQxXdmVBpXXrl2T9957T+bMmSMtWrQg0ARga+yzCb/SrOZrr70mr776qvTq1Uvy5s1rbtc328GDB8vMmTNNVjNnzpz+HioAAJbRpSOTJk2SDh06SPbs2aV06dISFhZm9pZes2aN2d6rSJEi/h4mAPiEYBN+xZstACA20y2+hg0bJvv37zf7TZcpU8b0KqA/AYCYgGATAYE3WwBAbKX7SceJE8ffwwAAyxFsImDwZgsAiI3cmwDREAhATEKDIAQM9260nAMBAMQW7sElgSaAmITMJgAAAADAcmQ2AQAAAACWI9gEAAAAAFiOYBMAAAAAYDmCTQAAAACA5Qg2AQAAAACWI9gEAAAAAFiOYBMAAAAAYDmCTQBArPfGG29I7dq1XdcrVqwonTp1euLjWLFihQQFBcmFCxee2M8aqOMEANgfwSYAICBpUKQBjV5CQkIke/bsMnDgQLlz5060v/bcuXNl0KBBARl4Zc6cWT799NMn8loAAPgirk/fDQBANKpWrZpMmTJFbt68KYsXL5b27dtLvHjxJDw83Ouxt27dMkGpFVKkSGHJ8wAAEJuR2QQABKzQ0FBJly6dZMqUSd5++22pXLmyLFy40KMcdMiQIZIhQwbJlSuXuf2ff/6RV199VZIlS2aCxlq1asnhw4ddz3n37l3p0qWLuT9lypTSo0cPcTgcHq8bsYxWg92ePXvKM888Y8akWdYvvvjCPG+lSpXMY5InT24ynDoude/ePRk6dKhkyZJF4sePL4UKFZLvv//e43U0gM6ZM6e5X5/HfZyPQ3+2li1bul5TfyefffbZfR87YMAASZ06tSRJkkTatm1rgnWnyIwdAIBHIbMJALANDXzOnj3rur58+XITLP3888/m+u3bt6Vq1apSunRp+f333yVu3LgyePBgkyHdunWryXwOHz5cpk6dKl9++aXkyZPHXJ83b548//zzD3zdZs2ayerVq2XUqFEm8Dp06JCcOXPGBJ9z5syRevXqyZ49e8xYdIxKg7Wvv/5aJkyYIDly5JDffvtNXn/9dRPgVahQwQTFdevWNdna1q1by4YNG6Rr164+/X40SHz66adl9uzZJpBetWqVee706dObANz99xYWFmZKgDXAffPNN83jNXCPzNgBAIgUBwAAAah58+aOWrVqma/v3bvn+Pnnnx2hoaGObt26ue5Pmzat4+bNm67vmT59uiNXrlzm8U56f/z48R1Lly4119OnT+/4+OOPXfffvn3b8fTTT7teS1WoUMHx7rvvmq/37NmjaU/z+vfz66+/mvvPnz/vuu3GjRuOBAkSOFatWuXx2JYtWzoaN25svg4PD3fkzZvX4/6ePXt6PVdEmTJlcowcOdIRWe3bt3fUq1fPdV1/bylSpHBcvXrVddv48eMdiRIlcty9ezdSY7/fzwwAQERkNgEAAWvRokWSKFEik7HUrN1rr70m/fv3d91foEABj3WaW7Zskf3790vixIk9nufGjRty4MABuXjxohw/flxKlizpuk+zn88++6xXKa3T5s2bJU6cOFHK6OkYrl27JlWqVPG4XUtVixQpYr7etWuXxziUZmR9NXbsWJO1PXLkiFy/ft28ZuHChT0eo9nZBAkSeLzulStXTLZV/33U2AEAiAyCTQBAwNJ1jOPHjzcBpa7L1MDQXcKECT2ua6BUrFgxmTFjhtdzaQno43CWxUaFjkP9+OOP8tRTT3ncp2s+o8usWbOkW7dupjRYA0gNuocNGyZr164N+LEDAGIegk0AQMDSYFKb8URW0aJF5dtvv5U0adKY9ZP3o+sXNfgqX768ua5bqWzcuNF87/1o9lSzqitXrjQNiiJyZla1OY9T3rx5TWCm2cUHZUR1vaiz2ZHTmjVrxBd//vmnlClTRtq1a+e6TTO6EWkGWLOezkBaX1czyLoGVZsqPWrsAABEBt1oAQAxRpMmTSRVqlSmA602CNJGPtoE55133pF///3XPObdd9+VDz/8UObPny+7d+82gdnD9sjUfS2bN28uLVq0MN/jfM7vvvvO3K+dcrULrZb8nj592mQGNaOoGcbOnTvLtGnTTMD3119/yejRo811pR1g9+3bJ927dzfNhWbOnGkaF0XG0aNHTXmv++X8+fOmmY82Glq6dKns3btX+vTpI+vXr/f6fi2J1a61O3fuNB1x+/XrJx06dJDg4OBIjR0AgMgg2AQAxBi6DlE7p2bMmNF0etXsoQZVumbTmenUjq9NmzY1AaSz1LROnToPfV4t5a1fv74JTHPnzi2tWrX6f+3dMQqEMBAFUPcUHsje1iN4BXvByuvaL39gYbfaFFO+B1aGkJSfZCbT8zz1L1dN84zIcRzTPM8V2uI8zwp76eyadaQjbq6m5jmRyBrTyTYBNjWU6fx6XdfQPu/7rvrJ7y9z7/te+962repB07n3+5TzY1mWCqY53c3YdV1/amH/rR0ARrzSJWhoJAAAAAxysgkAAEA7YRMAAIB2wiYAAADthE0AAADaCZsAAAC0EzYBAABoJ2wCAADQTtgEAACgnbAJAABAO2ETAACAdsImAAAA7YRNAAAApm5vBH4XJq14wHIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "print('🔮 Making predictions...')\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print('\\n📋 Classification Report:')\n",
    "print(classification_report(y_test, pred_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n🔍 Confusion Matrix:')\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved to: ../streamlit_app/models/bert_email_classifier\n",
      "Tokenizer saved to: ../streamlit_app/models/tokenizer\n",
      "Label encoder saved to: ../streamlit_app/models/label_encoder.pkl\n",
      "Results saved to: ../streamlit_app/models/training_results.json\n",
      "\n",
      "The model is ready to be used in the Streamlit app!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and components\n",
    "print('Saving model...')\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../streamlit_app/models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = '../streamlit_app/models/bert_email_classifier'\n",
    "trainer.save_model(model_path)\n",
    "print(f'Model saved to: {model_path}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer_path = '../streamlit_app/models/tokenizer'\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "print(f'Tokenizer saved to: {tokenizer_path}')\n",
    "\n",
    "# Save label encoder\n",
    "import pickle\n",
    "label_encoder_path = '../streamlit_app/models/label_encoder.pkl'\n",
    "with open(label_encoder_path, 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f'Label encoder saved to: {label_encoder_path}')\n",
    "\n",
    "# Save training results\n",
    "training_results = {\n",
    "    'model_name': model_name,\n",
    "    'num_classes': num_labels,\n",
    "    'classes': label_encoder.classes_.tolist(),\n",
    "    'evaluation_results': results,\n",
    "    'training_args': training_args.to_dict()\n",
    "}\n",
    "\n",
    "results_path = '../streamlit_app/models/training_results.json'\n",
    "import json\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(training_results, f, indent=2)\n",
    "print(f'Results saved to: {results_path}')\n",
    "\n",
    "print('\\nThe model is ready to be used in the Streamlit app!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just laod a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxxx\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the saved model and components\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading saved model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxx\n",
    "\n",
    "# Load the saved model and components\n",
    "print('Loading saved model...')\n",
    "\n",
    "# Load model\n",
    "model_path = '../streamlit_app/models/bert_email_classifier'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "print(f'Model loaded from: {model_path}')\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer_path = '../streamlit_app/models/tokenizer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "print(f'Tokenizer loaded from: {tokenizer_path}')\n",
    "\n",
    "# Load label encoder\n",
    "import pickle\n",
    "label_encoder_path = '../streamlit_app/models/label_encoder.pkl'\n",
    "with open(label_encoder_path, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "print(f'Label encoder loaded from: {label_encoder_path}')\n",
    "\n",
    "# Move model to device (MPS on your Mac)\n",
    "model = model.to(device)\n",
    "print(f'Model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing the model with sample emails:\n",
      "\n",
      "Email 1: My car was stolen from the parking lot last night....\n",
      "Predicted: CarTheft\n",
      "Confidence: 0.9890\n",
      "\n",
      "Email 2: I need to renew my car insurance policy before it ...\n",
      "Predicted: CarRenewal\n",
      "Confidence: 0.8601\n",
      "\n",
      "Email 3: My windshield has a large crack and needs to be re...\n",
      "Predicted: CarWindshield\n",
      "Confidence: 0.9747\n",
      "\n",
      "Email 4: My car broke down on the highway and I need roadsi...\n",
      "Predicted: CarBreakdown\n",
      "Confidence: 0.8580\n",
      "\n",
      "Email 5: I was involved in a car accident and need to repor...\n",
      "Predicted: CarCrash\n",
      "Confidence: 0.7634\n"
     ]
    }
   ],
   "source": [
    "# Test the model with some sample emails\n",
    "def predict_email(text):\n",
    "    \"\"\"Predict the category of an email\"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "    \n",
    "    return label_encoder.classes_[predicted_class], confidence\n",
    "\n",
    "# Test with some sample emails\n",
    "test_emails = [\n",
    "    \"My car was stolen from the parking lot last night. Please help me file a claim.\",\n",
    "    \"I need to renew my car insurance policy before it expires next month.\",\n",
    "    \"My windshield has a large crack and needs to be replaced.\",\n",
    "    \"My car broke down on the highway and I need roadside assistance.\",\n",
    "    \"I was involved in a car accident and need to report it.\"\n",
    "]\n",
    "\n",
    "print(\"🧪 Testing the model with sample emails:\")\n",
    "for i, email in enumerate(test_emails, 1):\n",
    "    predicted_label, confidence = predict_email(email)\n",
    "    print(f\"\\nEmail {i}: {email[:50]}...\")\n",
    "    print(f\"Predicted: {predicted_label}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".ui-container { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
       "               padding: 20px; border-radius: 15px; margin: 20px 0; color: white; }\n",
       ".ui-section { background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; margin: 15px 0; }\n",
       ".ui-button { background: linear-gradient(45deg, #ff6b6b, #ee5a24); border: none; color: white; \n",
       "            padding: 12px 24px; border-radius: 25px; font-size: 16px; font-weight: bold; }\n",
       ".ui-result { background: rgba(255,255,255,0.95); color: #333; padding: 15px; border-radius: 10px; \n",
       "            margin: 15px 0; border-left: 5px solid #667eea; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Setting up the Email Classification Dashboard...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba841cf609242c2bcbf1e2072b076aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<div class=\"ui-container\"><h1>📧 Email Classification Dashboard</h1></div>'), HTML(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dashboard loaded! Enter an email and click 'Classify Email' to test it.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SIMPLE NOTEBOOK UI - Copy this into a new cell in your notebook\n",
    "# =============================================================================\n",
    "\n",
    "# Install ipywidgets if needed:\n",
    "# !pip install ipywidgets\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Simple styling\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".ui-container { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "               padding: 20px; border-radius: 15px; margin: 20px 0; color: white; }\n",
    ".ui-section { background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; margin: 15px 0; }\n",
    ".ui-button { background: linear-gradient(45deg, #ff6b6b, #ee5a24); border: none; color: white; \n",
    "            padding: 12px 24px; border-radius: 25px; font-size: 16px; font-weight: bold; }\n",
    ".ui-result { background: rgba(255,255,255,0.95); color: #333; padding: 15px; border-radius: 10px; \n",
    "            margin: 15px 0; border-left: 5px solid #667eea; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Create the UI\n",
    "def create_simple_ui():\n",
    "    # Header\n",
    "    header = widgets.HTML(value='<div class=\"ui-container\"><h1>📧 Email Classification Dashboard</h1></div>')\n",
    "    \n",
    "    # Input fields\n",
    "    subject_input = widgets.Text(placeholder='Enter email subject...', description='Subject:', layout=widgets.Layout(width='100%'))\n",
    "    message_input = widgets.Textarea(placeholder='Enter email message...', description='Message:', layout=widgets.Layout(width='100%', height='100px'))\n",
    "    \n",
    "    # Classify button\n",
    "    classify_button = widgets.Button(description='Classify Email', button_style='success', layout=widgets.Layout(width='200px'))\n",
    "    \n",
    "    # Result display\n",
    "    result_output = widgets.HTML(value='<div class=\"ui-result\">Enter an email above and click \"Classify Email\" to get started!</div>')\n",
    "    \n",
    "    # Classification function\n",
    "    def on_classify_click(b):\n",
    "        subject = subject_input.value.strip()\n",
    "        message = message_input.value.strip()\n",
    "        \n",
    "        if not subject and not message:\n",
    "            result_output.value = '<div class=\"ui-result\" style=\"border-left-color: #ff6b6b;\">⚠️ Please enter either a subject or message.</div>'\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Combine text\n",
    "            full_text = f\"{subject} {message}\".strip()\n",
    "            \n",
    "            # Get prediction using the predict_email function from earlier in the notebook\n",
    "            predicted_label, confidence = predict_email(full_text)\n",
    "            \n",
    "            # Color code based on confidence\n",
    "            if confidence > 0.8:\n",
    "                border_color = \"#28a745\"  # Green\n",
    "            elif confidence > 0.6:\n",
    "                border_color = \"#ffc107\"  # Yellow\n",
    "            else:\n",
    "                border_color = \"#dc3545\"  # Red\n",
    "            \n",
    "            result_html = f\"\"\"\n",
    "            <div class=\"ui-result\" style=\"border-left-color: {border_color};\">\n",
    "                <h4>🎯 Classification Result</h4>\n",
    "                <p><strong>Category:</strong> <span style=\"color: {border_color}; font-weight: bold;\">{predicted_label}</span></p>\n",
    "                <p><strong>Confidence:</strong> {confidence:.1%}</p>\n",
    "                <p><strong>Input:</strong> {full_text[:100]}{'...' if len(full_text) > 100 else ''}</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            result_output.value = result_html\n",
    "            \n",
    "        except Exception as e:\n",
    "            result_output.value = f'<div class=\"ui-result\" style=\"border-left-color: #dc3545;\"> Error: {str(e)}</div>'\n",
    "    \n",
    "    classify_button.on_click(on_classify_click)\n",
    "    \n",
    "    # Layout\n",
    "    ui = widgets.VBox([\n",
    "        header,\n",
    "        widgets.HTML(value='<div class=\"ui-section\"><h3>🔍 Email Classification</h3></div>'),\n",
    "        subject_input,\n",
    "        message_input,\n",
    "        classify_button,\n",
    "        result_output\n",
    "    ])\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Display the UI\n",
    "print(\"🎨 Setting up the Email Classification Dashboard...\")\n",
    "ui = create_simple_ui()\n",
    "display(ui)\n",
    "print(\"✅ Dashboard loaded! Enter an email and click 'Classify Email' to test it.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE  for the MOMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: car stolen my car was stolen how do i claim for this theft\n",
      "Predicted: CarTheft (88.9%)\n",
      "All probabilities: ['1.5%', '2.0%', '2.1%', '88.9%', '2.6%', '2.9%']\n",
      "\n",
      "Text: my windshield is cracked and needs repair\n",
      "Predicted: CarWindshield (38.2%)\n",
      "All probabilities: ['27.5%', '8.9%', '7.6%', '6.5%', '38.2%', '11.3%']\n",
      "\n",
      "Text: car broke down on the highway\n",
      "Predicted: CarBreakdown (45.1%)\n",
      "All probabilities: ['45.1%', '33.2%', '4.6%', '7.9%', '5.6%', '3.6%']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_texts = [\n",
    "    \"car stolen my car was stolen how do i claim for this theft\",\n",
    "    \"my windshield is cracked and needs repair\",\n",
    "    \"car broke down on the highway\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Predicted: {label_encoder.classes_[predicted_class]} ({confidence:.1%})\")\n",
    "    print(f\"All probabilities: {[f'{p:.1%}' for p in probabilities[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model moved to: cpu\n",
      "\n",
      "🔍 Test: car stolen my car was stolen how do i claim for this theft\n",
      "�� Predicted: CarCrash (33.3%)\n",
      "📊 All probabilities:\n",
      "   CarBreakdown: 19.0%\n",
      "   CarCrash: 33.3%\n",
      "   CarRenewal: 6.3%\n",
      "   CarTheft: 21.2%\n",
      "   CarWindshield: 12.9%\n",
      "   Other: 7.3%\n"
     ]
    }
   ],
   "source": [
    "# Force CPU mode to avoid MPS issues\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "tokenizer = tokenizer\n",
    "\n",
    "print(f\"✅ Model moved to: {device}\")\n",
    "\n",
    "# Now test the prediction\n",
    "test_text = \"car stolen my car was stolen how do i claim for this theft\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Move inputs to CPU\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "\n",
    "print(f\"\\n🔍 Test: {test_text}\")\n",
    "print(f\"�� Predicted: {label_encoder.classes_[predicted_class]} ({confidence:.1%})\")\n",
    "print(f\"📊 All probabilities:\")\n",
    "for i, prob in enumerate(probabilities[0]):\n",
    "    print(f\"   {label_encoder.classes_[i]}: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     probabilities = torch.softmax(outputs.logits, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     15\u001b[39m     predicted_class = torch.argmax(probabilities, dim=\u001b[32m1\u001b[39m).item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_distilbert.py:917\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    909\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    910\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    911\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    912\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    914\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    915\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m distilbert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    927\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_distilbert.py:723\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    720\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    721\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_flash_attention_2:\n\u001b[32m    726\u001b[39m     attention_mask = attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_distilbert.py:111\u001b[39m, in \u001b[36mEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, input_embeds)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \u001b[33;03membeddings)\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     input_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[32m    113\u001b[39m seq_length = input_embeds.size(\u001b[32m1\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# issues similar to issue #5664\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/emailClassify/venv/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    \"my car was stolen from the parking lot\",\n",
    "    \"windshield cracked and needs repair\", \n",
    "    \"car broke down on highway\",\n",
    "    \"need to renew car insurance\",\n",
    "    \"car accident damage claim\"\n",
    "]\n",
    "\n",
    "for text in test_cases:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    print(f\"\\nest: {text}\")\n",
    "    print(f\"Predicted: {label_encoder.classes_[predicted_class]} ({confidence:.1%})\")\n",
    "    \n",
    "    # Show top 2 predictions\n",
    "    top_probs, top_indices = torch.topk(probabilities[0], 2)\n",
    "    for i, (prob, idx) in enumerate(zip(top_probs, top_indices)):\n",
    "        print(f\"   {i+1}. {label_encoder.classes_[idx]}: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model moved to: cpu\n",
      "\n",
      "🔍 Test: my car was stolen from the parking lot\n",
      "�� Predicted: CarTheft (79.1%)\n",
      "📊 All probabilities:\n",
      "   CarBreakdown: 4.4%\n",
      "   CarCrash: 4.7%\n",
      "   CarRenewal: 2.6%\n",
      "   CarTheft: 79.1%\n",
      "   CarWindshield: 5.0%\n",
      "   Other: 4.1%\n"
     ]
    }
   ],
   "source": [
    "# Force CPU mode again to avoid MPS issues\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model moved to: {device}\")\n",
    "\n",
    "# Now test the prediction\n",
    "test_text = \"my car was stolen from the parking lot\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Move inputs to CPU\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "\n",
    "print(f\"\\n🔍 Test: {test_text}\")\n",
    "print(f\"�� Predicted: {label_encoder.classes_[predicted_class]} ({confidence:.1%})\")\n",
    "print(f\"📊 All probabilities:\")\n",
    "for i, prob in enumerate(probabilities[0]):\n",
    "    print(f\"   {label_encoder.classes_[i]}: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "�� Test: windshield cracked and needs repair\n",
      "�� Predicted: CarWindshield (57.4%)\n",
      "   1. CarWindshield: 57.4%\n",
      "   2. CarBreakdown: 13.5%\n",
      "\n",
      "�� Test: car broke down on highway\n",
      "�� Predicted: CarBreakdown (43.5%)\n",
      "   1. CarBreakdown: 43.5%\n",
      "   2. CarCrash: 37.7%\n",
      "\n",
      "�� Test: need to renew car insurance\n",
      "�� Predicted: CarRenewal (53.8%)\n",
      "   1. CarRenewal: 53.8%\n",
      "   2. Other: 25.9%\n",
      "\n",
      "�� Test: car accident damage claim\n",
      "�� Predicted: CarCrash (87.4%)\n",
      "   1. CarCrash: 87.4%\n",
      "   2. CarTheft: 5.5%\n"
     ]
    }
   ],
   "source": [
    "# Test all categories to see the improvements\n",
    "test_cases = [\n",
    "    \"windshield cracked and needs repair\",\n",
    "    \"car broke down on highway\", \n",
    "    \"need to renew car insurance\",\n",
    "    \"car accident damage claim\"\n",
    "]\n",
    "\n",
    "for text in test_cases:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    print(f\"\\nTest: {text}\")\n",
    "    print(f\"Predicted: {label_encoder.classes_[predicted_class]} ({confidence:.1%})\")\n",
    "    \n",
    "    # Show top 2 predictions\n",
    "    top_probs, top_indices = torch.topk(probabilities[0], 2)\n",
    "    for i, (prob, idx) in enumerate(zip(top_probs, top_indices)):\n",
    "        print(f\"   {i+1}. {label_encoder.classes_[idx]}: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a pirate</s>\n",
      "<|user|>\n",
      "How many helicopters can a human eat in one sitting?</s>\n",
      "<|assistant|>\n",
      "Unfortunately, there is no scientific evidence to support this claim. It is purely anecdotal and not backed by any credible sources. While humans can consume large amounts of food, the consumption of helicopters is not a recommended practice as it could lead to digestive issues, allergic reactions, and even death. It is recommended to avoid consuming large amounts of helicopters in one sitting, as it can lead to health concerns.\n"
     ]
    }
   ],
   "source": [
    "# Install transformers from source - only needed for versions <= v4.34\n",
    "# pip install git+https://github.com/huggingface/transformers.git\n",
    "# pip install accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a customer service agent who reads messages about car insurance. You class the messages into categories of Car Breakdown, Car Crash, Car Renewal, Car Theft, Car Windshield, Other. answer with only those categories</s>\n",
      "<|user|>\n",
      "windshield cracked and needs repair</s>\n",
      "<|assistant|>\n",
      "Car Breakdown\n",
      "- Cracked windshield due to accident or natural causes\n",
      "- Torn windshield due to road debris or tree branches\n",
      "- Leaking windshield due to leaks or punctures\n",
      "\n",
      "Car Crash\n",
      "- Crash caused by vehicle collision, such as collision with another vehicle, pedestrian, or object\n",
      "- Crash caused by a sudden stop or lane change\n",
      "- Crash caused by a driver's negligence or intoxication\n",
      "\n",
      "Car Renewal\n",
      "- Damaged or missing windshield during previous renewal\n",
      "- Windshield damage caused by hail or extreme weather conditions\n",
      "- Windshield damage caused by driving in extreme temperatures or humidity\n",
      "\n",
      "Car Theft\n",
      "- Theft caused by a thief intentionally breaking into a vehicle to steal the windshield\n",
      "- Theft caused by a thief who broke into the vehicle but failed to steal the windshield\n",
      "- Theft caused by a thief who stole the car and damaged the windshield in the process\n",
      "\n",
      "Car Windshield\n",
      "- Damage caused by wind or rain\n",
      "- Damage caused by natural weather conditions or damage to\n"
     ]
    }
   ],
   "source": [
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a customer service agent who reads messages about car insurance. You class the messages into categories of Car Breakdown, Car Crash, Car Renewal, Car Theft, Car Windshield, Other. answer with only those categories\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"windshield cracked and needs repair\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After a rear-\n"
     ]
    }
   ],
   "source": [
    "labels = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": (\n",
    "         \"You are an email triage classifier for a car insurer.\\n\"\n",
    "         \"CLASS LABELS (must choose exactly one): CarBreakdown, CarCrash, CarRenewal, CarTheft, CarWindshield, Other.\\n\"\n",
    "         \"Rules:\\n\"\n",
    "         \"1) Output exactly ONE label from the list above.\\n\"\n",
    "         \"2) Output ONLY the label text. No punctuation, no quotes, no explanation.\\n\"\n",
    "         \"Quick guide:\\n\"\n",
    "         \"- CarBreakdown: engine won’t start, tow, battery, stranded, overheating.\\n\"\n",
    "         \"- CarCrash: collisions, rear-ended, hit, accident, damage from impact.\\n\"\n",
    "         \"- CarRenewal: renewal prices, add driver at renewal, change car for renewal.\\n\"\n",
    "         \"- CarTheft: stolen, theft, break-in, police report for theft.\\n\"\n",
    "         \"- CarWindshield: windscreen/windshield/glass crack/chip.\\n\"\n",
    "         \"- Other: general policy/portal/docs questions not covered above.\"\n",
    "     )\n",
    "    },\n",
    "\n",
    "    # a couple of compact few-shot examples to anchor the format\n",
    "    {\"role\": \"user\", \"content\": \"engine died at junction, need a tow to a garage\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"CarBreakdown\"},\n",
    "\n",
    "    {\"role\": \"user\", \"content\": \"rear ended at lights, no injuries\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"CarCrash\"},\n",
    "\n",
    "    # your actual query\n",
    "    {\"role\": \"user\", \"content\": \"rear ended at lights, no injuries. Car only damaged. what do i do after a crash\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Deterministic, short completion, no sampling\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=4,          # short, all labels < 4 tokens\n",
    "    do_sample=False,\n",
    "    temperature=0.0,\n",
    "    top_k=0,\n",
    "    top_p=1.0,\n",
    "    return_full_text=False,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarRenewal\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "labels = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "tok = pipe.tokenizer\n",
    "model = pipe.model\n",
    "\n",
    "# Build token-id sequences for each label\n",
    "label_token_seqs = [tok(lab, add_special_tokens=False)[\"input_ids\"] for lab in labels]\n",
    "\n",
    "# Build a simple trie over token ids\n",
    "TRIE_END = -1\n",
    "def build_trie(seqs):\n",
    "    root = {}\n",
    "    for idx, seq in enumerate(seqs):\n",
    "        node = root\n",
    "        for tid in seq:\n",
    "            node = node.setdefault(tid, {})\n",
    "        node[TRIE_END] = idx  # mark end-of-label\n",
    "    return root\n",
    "\n",
    "trie = build_trie(label_token_seqs)\n",
    "\n",
    "# Make the prompt as before\n",
    "prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "# Allowed-next-tokens function, applied only on the generated suffix\n",
    "def allowed_next_tokens_fn(batch_id, full_ids):\n",
    "    # only consider what has been generated after the prompt\n",
    "    gen_ids = full_ids[input_len:]\n",
    "    node = trie\n",
    "\n",
    "    # Walk the trie according to the generated suffix\n",
    "    for tid in gen_ids.tolist():\n",
    "        if tid in node:\n",
    "            node = node[tid]\n",
    "            # If a label just finished, only allow EOS to end immediately\n",
    "            if TRIE_END in node:\n",
    "                return [tok.eos_token_id]\n",
    "        else:\n",
    "            # If it diverged, only allow starting a label from scratch\n",
    "            node = trie\n",
    "            break\n",
    "\n",
    "    # Allowed continuations are the children keys; if none, allow EOS\n",
    "    allowed = list(node.keys())\n",
    "    return allowed if allowed else [tok.eos_token_id]\n",
    "\n",
    "# Generate: greedy, short, constrained\n",
    "with torch.inference_mode():\n",
    "    out_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=8,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tok.eos_token_id,\n",
    "        pad_token_id=tok.eos_token_id,\n",
    "        prefix_allowed_tokens_fn=allowed_next_tokens_fn,\n",
    "    )\n",
    "\n",
    "completion = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "print(completion)  # will be exactly one of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: windshield cracked and needs repair\n",
      "PRED : Other\n",
      "INPUT: premium went up 20% at renewal, can I add a named driver?\n",
      "PRED : Other\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "LABELS = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "def score_label_with_llm(user_text, pipe):\n",
    "    tok = pipe.tokenizer\n",
    "    model = pipe.model\n",
    "    model.eval()\n",
    "\n",
    "    # Build prompt once\n",
    "    system_text = (\n",
    "        \"You are an email triage classifier for a car insurer. \"\n",
    "        \"Choose exactly one class for the user's message.\"\n",
    "    )\n",
    "    messages = [{\"role\":\"system\",\"content\":system_text},\n",
    "                {\"role\":\"user\",\"content\":user_text}]\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    prompt_ids = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    scores = []\n",
    "    with torch.inference_mode():\n",
    "        for lab in LABELS:\n",
    "            lab_ids = tok(lab, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "            # Concatenate prompt + label\n",
    "            input_ids = torch.cat([prompt_ids[\"input_ids\"], lab_ids[\"input_ids\"]], dim=1)\n",
    "            # Only compute loss on the label tokens\n",
    "            labels = input_ids.clone()\n",
    "            labels[:, :prompt_ids[\"input_ids\"].shape[1]] = -100\n",
    "            out = model(input_ids=input_ids, labels=labels)\n",
    "            # Convert mean CE loss to total log-prob (higher is better)\n",
    "            label_token_count = (labels != -100).sum().item()\n",
    "            nll = out.loss.item() * label_token_count\n",
    "            scores.append(-nll)\n",
    "\n",
    "    best = LABELS[int(torch.tensor(scores).argmax().item())]\n",
    "    return best\n",
    "\n",
    "# Test\n",
    "print(\"INPUT:\", \"windshield cracked and needs repair\")\n",
    "print(\"PRED :\", score_label_with_llm(\"windshield cracked and needs repair\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"premium went up 20% at renewal, can I add a named driver?\")\n",
    "print(\"PRED :\", score_label_with_llm(\"premium went up 20% at renewal, can I add a named driver?\", pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: windshield cracked and needs repair\n",
      "PRED : CarRenewal\n",
      "INPUT: premium went up 20% at renewal, can I add a named driver?\n",
      "PRED : CarRenewal\n"
     ]
    }
   ],
   "source": [
    "# One short example per class (balanced few-shot)\n",
    "choices = {\n",
    "    \"A\": \"CarBreakdown\",\n",
    "    \"B\": \"CarCrash\",\n",
    "    \"C\": \"CarRenewal\",\n",
    "    \"D\": \"CarTheft\",\n",
    "    \"E\": \"CarWindshield\",\n",
    "    \"F\": \"Other\",\n",
    "}\n",
    "\n",
    "system_text = (\n",
    "    \"Classify the user's message into EXACTLY ONE of these classes by replying ONLY with a single letter:\\n\"\n",
    "    \"A) CarBreakdown  B) CarCrash  C) CarRenewal  D) CarTheft  E) CarWindshield  F) Other\"\n",
    ")\n",
    "\n",
    "few_shot = [\n",
    "    (\"engine died at junction, need a tow\",               \"A\"),\n",
    "    (\"rear ended at the lights, no injuries\",             \"B\"),\n",
    "    (\"renewal price up 20%, can I add a driver?\",         \"C\"),\n",
    "    (\"my car was stolen overnight, police ref 123\",       \"D\"),\n",
    "    (\"windshield cracked by stone on motorway\",           \"E\"),\n",
    "    (\"where do I download my insurance disc?\",            \"F\"),\n",
    "]\n",
    "\n",
    "def build_messages(user_text):\n",
    "    msgs = [{\"role\":\"system\",\"content\":system_text}]\n",
    "    for u, a in few_shot:\n",
    "        msgs += [{\"role\":\"user\",\"content\":u},{\"role\":\"assistant\",\"content\":a}]\n",
    "    msgs += [{\"role\":\"user\",\"content\":user_text}]\n",
    "    return msgs\n",
    "\n",
    "def classify_letter(user_text, pipe):\n",
    "    tok = pipe.tokenizer\n",
    "    model = pipe.model\n",
    "    messages = build_messages(user_text)\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # Constrain to A–F (and optionally lowercase a–f)\n",
    "    allowed_tokens = set()\n",
    "    for ch in list(\"ABCDEFabcdef\"):\n",
    "        ids = tok(ch, add_special_tokens=False)[\"input_ids\"]\n",
    "        # allow only single-token letters; if multi-token, we'll just fall back to greedy\n",
    "        if len(ids) == 1:\n",
    "            allowed_tokens.add(ids[0])\n",
    "\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    def prefix_allowed_tokens_fn(batch_id, full_ids):\n",
    "        # after prompt, only allow a single letter token\n",
    "        if len(full_ids[input_len:]) == 0:\n",
    "            return list(allowed_tokens) if allowed_tokens else None\n",
    "        # after first token, force EOS\n",
    "        return [tok.eos_token_id]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2,\n",
    "            do_sample=False,\n",
    "            return_dict_in_generate=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            prefix_allowed_tokens_fn=(prefix_allowed_tokens_fn if allowed_tokens else None),\n",
    "        )\n",
    "\n",
    "    gen = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "    letter = gen[:1].upper()  # first char only\n",
    "    return choices.get(letter, \"Other\")\n",
    "\n",
    "# Test\n",
    "print(\"INPUT:\", \"windshield cracked and needs repair\")\n",
    "print(\"PRED :\", classify_letter(\"windshield cracked and needs repair\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"premium went up 20% at renewal, can I add a named driver?\")\n",
    "print(\"PRED :\", classify_letter(\"premium went up 20% at renewal, can I add a named driver?\", pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: windshield cracked and needs repair\n",
      "PRED : CarRenewal\n",
      "INPUT: premium went up 20% at renewal, can I add a named driver?\n",
      "PRED : CarRenewal\n",
      "INPUT: my car crashed into another car?\n",
      "PRED : CarRenewal\n"
     ]
    }
   ],
   "source": [
    "def classify_with_llm(user_text, pipe, few_shot=True):\n",
    "    tok = pipe.tokenizer\n",
    "    model = pipe.model\n",
    "\n",
    "    labels = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "    system_text = (\n",
    "        \"You are an email triage classifier for a car insurer.\\n\"\n",
    "        \"CLASS LABELS (must choose exactly one): CarBreakdown, CarCrash, CarRenewal, CarTheft, CarWindshield, Other.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1) Output exactly ONE label from the list above.\\n\"\n",
    "        \"2) Output ONLY the label text. No punctuation, no quotes, no explanation.\\n\"\n",
    "        \"Quick guide:\\n\"\n",
    "        \"- CarBreakdown: engine won’t start, tow, battery, stranded, overheating.\\n\"\n",
    "        \"- CarCrash: collisions, rear-ended, hit, accident, damage from impact.\\n\"\n",
    "        \"- CarRenewal: renewal\\n\"\n",
    "        \"- CarTheft: stolen, theft, break-in, taken robbed, police report for theft.\\n\"\n",
    "        \"- CarWindshield: windscreen windshield glass crack chip.\\n\"\n",
    "        \"- Other: general policy/portal/docs questions not covered above.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\":\"system\",\"content\":system_text}]\n",
    "    if few_shot:\n",
    "        messages += [\n",
    "            {\"role\":\"user\",\"content\":\"engine died at junction, need a tow to a garage\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarBreakdown\"},\n",
    "            {\"role\":\"user\",\"content\":\"rear ended at lights, no injuries\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarCrash\"},\n",
    "            {\"role\":\"user\",\"content\":\"my windscreen got cracked while driving\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarWindshield\"},\n",
    "        ]\n",
    "    # 👇 YOUR INPUT GOES HERE\n",
    "    messages += [{\"role\":\"user\",\"content\":user_text}]\n",
    "\n",
    "    # ---- constrained decoding bits (same as before) ----\n",
    "    label_token_seqs = [tok(l, add_special_tokens=False)[\"input_ids\"] for l in labels]\n",
    "    TRIE_END = -1\n",
    "    def build_trie(seqs):\n",
    "        root = {}\n",
    "        for idx, seq in enumerate(seqs):\n",
    "            node = root\n",
    "            for tid in seq:\n",
    "                node = node.setdefault(tid, {})\n",
    "            node[TRIE_END] = idx\n",
    "        return root\n",
    "    trie = build_trie(label_token_seqs)\n",
    "\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    def allowed_next_tokens_fn(batch_id, full_ids):\n",
    "        gen_ids = full_ids[input_len:]\n",
    "        node = trie\n",
    "        for tid in gen_ids.tolist():\n",
    "            if tid in node:\n",
    "                node = node[tid]\n",
    "                if TRIE_END in node:\n",
    "                    return [tok.eos_token_id]\n",
    "            else:\n",
    "                node = trie\n",
    "                break\n",
    "        allowed = list(node.keys())\n",
    "        return allowed if allowed else [tok.eos_token_id]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=8,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            prefix_allowed_tokens_fn=allowed_next_tokens_fn,\n",
    "        )\n",
    "\n",
    "    label = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "    return label\n",
    "\n",
    "# Examples\n",
    "print(\"INPUT:\", \"windshield cracked and needs repair\")\n",
    "print(\"PRED :\", classify_with_llm(\"windshield cracked and needs repair\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"premium went up 20% at renewal, can I add a named driver?\")\n",
    "print(\"PRED :\", classify_with_llm(\"premium went up 20% at renewal, can I add a named driver?\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"my car crashed into another car?\")\n",
    "print(\"PRED :\", classify_with_llm(\"my car crashed into another car?\", pipe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: windshield cracked and needs repair\n",
      "PRED : CarRenewal\n",
      "INPUT: premium went up 20% at renewal, can I add a named driver?\n",
      "PRED : CarRenewal\n",
      "INPUT: my car crashed into another car?\n",
      "PRED : CarRenewal\n"
     ]
    }
   ],
   "source": [
    "def classify_with_llm(user_text, pipe, few_shot=True):\n",
    "    tok = pipe.tokenizer\n",
    "    model = pipe.model\n",
    "\n",
    "    labels = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "    system_text = (\n",
    "        \"You are an email triage classifier for a car insurer.\\n\"\n",
    "        \"CLASS LABELS (must choose exactly one): CarBreakdown, CarCrash, CarRenewal, CarTheft, CarWindshield, Other.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1) Output exactly ONE label from the list above.\\n\"\n",
    "        \"2) Output ONLY the label text. No punctuation, no quotes, no explanation.\\n\"\n",
    "        \"Quick guide:\\n\"\n",
    "        \"- CarBreakdown: engine won’t start, tow, battery, stranded, overheating.\\n\"\n",
    "        \"- CarCrash: collisions, rear-ended, hit, accident, damage from impact.\\n\"\n",
    "        \"- CarRenewal: renewal\\n\"\n",
    "        \"- CarTheft: stolen, theft, break-in, taken robbed, police report for theft.\\n\"\n",
    "        \"- CarWindshield: windscreen windshield glass crack chip.\\n\"\n",
    "        \"- Other: general policy/portal/docs questions not covered above.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\":\"system\",\"content\":system_text}]\n",
    "    if few_shot:\n",
    "        messages += [\n",
    "            {\"role\":\"user\",\"content\":\"engine died at junction, need a tow to a garage\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarBreakdown\"},\n",
    "            {\"role\":\"user\",\"content\":\"rear ended at lights, no injuries\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarCrash\"},\n",
    "            {\"role\":\"user\",\"content\":\"my windscreen got cracked while driving\"},\n",
    "            {\"role\":\"assistant\",\"content\":\"CarWindshield\"},\n",
    "        ]\n",
    "    # 👇 YOUR INPUT GOES HERE\n",
    "    messages += [{\"role\":\"user\",\"content\":user_text}]\n",
    "\n",
    "    # ---- constrained decoding bits (same as before) ----\n",
    "    label_token_seqs = [tok(l, add_special_tokens=False)[\"input_ids\"] for l in labels]\n",
    "    TRIE_END = -1\n",
    "    def build_trie(seqs):\n",
    "        root = {}\n",
    "        for idx, seq in enumerate(seqs):\n",
    "            node = root\n",
    "            for tid in seq:\n",
    "                node = node.setdefault(tid, {})\n",
    "            node[TRIE_END] = idx\n",
    "        return root\n",
    "    trie = build_trie(label_token_seqs)\n",
    "\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    def allowed_next_tokens_fn(batch_id, full_ids):\n",
    "        gen_ids = full_ids[input_len:]\n",
    "        node = trie\n",
    "        for tid in gen_ids.tolist():\n",
    "            if tid in node:\n",
    "                node = node[tid]\n",
    "                if TRIE_END in node:\n",
    "                    return [tok.eos_token_id]\n",
    "            else:\n",
    "                node = trie\n",
    "                break\n",
    "        allowed = list(node.keys())\n",
    "        return allowed if allowed else [tok.eos_token_id]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=8,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            prefix_allowed_tokens_fn=allowed_next_tokens_fn,\n",
    "        )\n",
    "\n",
    "    label = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "    return label\n",
    "\n",
    "# Examples\n",
    "print(\"INPUT:\", \"windshield cracked and needs repair\")\n",
    "print(\"PRED :\", classify_with_llm(\"windshield cracked and needs repair\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"premium went up 20% at renewal, can I add a named driver?\")\n",
    "print(\"PRED :\", classify_with_llm(\"premium went up 20% at renewal, can I add a named driver?\", pipe))\n",
    "\n",
    "print(\"INPUT:\", \"my car crashed into another car?\")\n",
    "print(\"PRED :\", classify_with_llm(\"my car crashed into another car?\", pipe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "LABELS = [\"CarBreakdown\",\"CarCrash\",\"CarRenewal\",\"CarTheft\",\"CarWindshield\",\"Other\"]\n",
    "\n",
    "def classify_llm_ranker(user_text, pipe, labels=LABELS):\n",
    "    tok, model = pipe.tokenizer, pipe.model\n",
    "    model.eval()\n",
    "\n",
    "    # Minimal, neutral prompt to reduce bias\n",
    "    system_text = \"Classify the user's message into exactly one label.\"\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": system_text},\n",
    "        {\"role\":\"user\",   \"content\": user_text}\n",
    "    ]\n",
    "\n",
    "    if hasattr(tok, \"apply_chat_template\"):\n",
    "        prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    else:\n",
    "        prompt = f\"[SYSTEM]{system_text}\\n[USER]{user_text}\\n[ASSISTANT]\"\n",
    "\n",
    "    prompt_ids = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    scores = []\n",
    "    with torch.inference_mode():\n",
    "        for lab in labels:\n",
    "            lab_ids = tok(lab, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "            # prompt + label\n",
    "            input_ids = torch.cat([prompt_ids[\"input_ids\"], lab_ids[\"input_ids\"]], dim=1)\n",
    "            # only score the label tokens\n",
    "            labels_ids = input_ids.clone()\n",
    "            labels_ids[:, :prompt_ids[\"input_ids\"].shape[1]] = -100\n",
    "            out = model(input_ids=input_ids, labels=labels_ids)\n",
    "            # convert mean loss to total NLL so different lengths are fair\n",
    "            L = (labels_ids != -100).sum().item()\n",
    "            nll = out.loss.item() * L\n",
    "            scores.append(-nll)  # higher = better\n",
    "\n",
    "    best_idx = int(torch.tensor(scores).argmax().item())\n",
    "    return labels[best_idx], dict(zip(labels, scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other\n",
      "Other\n",
      "Other\n"
     ]
    }
   ],
   "source": [
    "print(classify_llm_ranker(\"windshield cracked and needs repair\", pipe)[0])  # -> CarWindshield\n",
    "print(classify_llm_ranker(\"premium went up 20% at renewal, can I add a named driver?\", pipe)[0])  # -> CarRenewal\n",
    "print(classify_llm_ranker(\"my car crashed into another car?\", pipe)[0])  # -> CarCrash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_MAP = {\n",
    "    \"A\":\"CarBreakdown\", \"B\":\"CarCrash\", \"C\":\"CarRenewal\",\n",
    "    \"D\":\"CarTheft\", \"E\":\"CarWindshield\", \"F\":\"Other\"\n",
    "}\n",
    "\n",
    "def classify_letter(user_text, pipe):\n",
    "    tok, model = pipe.tokenizer, pipe.model\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\n",
    "         \"content\":\"Reply with a single letter for the best class: A) CarBreakdown  B) CarCrash  C) CarRenewal  D) CarTheft  E) CarWindshield  F) Other\"},\n",
    "        {\"role\":\"user\", \"content\":\"engine died at junction, need a tow\"},   {\"role\":\"assistant\",\"content\":\"A\"},\n",
    "        {\"role\":\"user\", \"content\":\"rear ended at lights, no injuries\"},      {\"role\":\"assistant\",\"content\":\"B\"},\n",
    "        {\"role\":\"user\", \"content\":\"renewal up 20%, add named driver?\"},      {\"role\":\"assistant\",\"content\":\"C\"},\n",
    "        {\"role\":\"user\", \"content\":\"car stolen overnight, police ref 123\"},   {\"role\":\"assistant\",\"content\":\"D\"},\n",
    "        {\"role\":\"user\", \"content\":\"stone cracked windshield on motorway\"},   {\"role\":\"assistant\",\"content\":\"E\"},\n",
    "        {\"role\":\"user\", \"content\":\"where can I download my cert?\"},          {\"role\":\"assistant\",\"content\":\"F\"},\n",
    "        {\"role\":\"user\", \"content\": user_text}\n",
    "    ]\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Constrain to single-token letters if available\n",
    "    allowed = {tok(ch, add_special_tokens=False)[\"input_ids\"][0]\n",
    "               for ch in \"ABCDEF\" if len(tok(ch, add_special_tokens=False)[\"input_ids\"])==1}\n",
    "\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    def prefix_allowed_tokens_fn(batch_id, full_ids):\n",
    "        gen = full_ids[input_len:]\n",
    "        if len(gen)==0:\n",
    "            return list(allowed) if allowed else None\n",
    "        return [tok.eos_token_id]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            prefix_allowed_tokens_fn=(prefix_allowed_tokens_fn if len(allowed)>0 else None),\n",
    "        )\n",
    "\n",
    "    txt = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "    return LETTER_MAP.get(txt[:1].upper(), \"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "C\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "print(classify_letter(\"windshield cracked and needs repair\", pipe)[0])  # -> CarWindshield\n",
    "print(classify_letter(\"premium went up 20% at renewal, can I add a named driver?\", pipe)[0])  # -> CarRenewal\n",
    "print(classify_letter(\"my car crashed into another car?\", pipe)[0])  # -> CarCrash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"   # or \"google/gemma-2-2b-it\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32),\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from bitsandbytes) (1.16.1)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /Users/davidcurran/Documents/emailClassify/venv/lib/python3.13/site-packages (from scipy->bitsandbytes) (2.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other\n",
      "Other\n",
      "Other\n"
     ]
    }
   ],
   "source": [
    "# Map 1..6 → your labels\n",
    "IDX2LABEL = {\n",
    "    \"1\":\"CarBreakdown\",\n",
    "    \"2\":\"CarCrash\",\n",
    "    \"3\":\"CarRenewal\",\n",
    "    \"4\":\"CarTheft\",\n",
    "    \"5\":\"CarWindshield\",\n",
    "    \"6\":\"Other\",\n",
    "}\n",
    "\n",
    "def classify_digits(user_text, pipe):\n",
    "    tok, model = pipe.tokenizer, pipe.model\n",
    "    msgs = [\n",
    "        {\"role\":\"system\",\"content\":\"Reply with ONE digit only: 1=CarBreakdown 2=CarCrash 3=CarRenewal 4=CarTheft 5=CarWindshield 6=Other\"},\n",
    "        {\"role\":\"user\",\"content\":\"engine died at junction, need a tow\"}, {\"role\":\"assistant\",\"content\":\"1\"},\n",
    "        {\"role\":\"user\",\"content\":\"rear ended at lights, no injuries\"},   {\"role\":\"assistant\",\"content\":\"2\"},\n",
    "        {\"role\":\"user\",\"content\":\"renewal up 20%, add named driver?\"},   {\"role\":\"assistant\",\"content\":\"3\"},\n",
    "        {\"role\":\"user\",\"content\":\"car stolen overnight, police ref 123\"},{\"role\":\"assistant\",\"content\":\"4\"},\n",
    "        {\"role\":\"user\",\"content\":\"stone cracked windshield on motorway\"},{\"role\":\"assistant\",\"content\":\"5\"},\n",
    "        {\"role\":\"user\",\"content\":\"where can I download my cert?\"},       {\"role\":\"assistant\",\"content\":\"6\"},\n",
    "        {\"role\":\"user\",\"content\":user_text}\n",
    "    ]\n",
    "    prompt = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Constrain to single-token digits 1..6 (if available)\n",
    "    allowed = []\n",
    "    for d in \"123456\":\n",
    "        ids = tok(d, add_special_tokens=False)[\"input_ids\"]\n",
    "        if len(ids) == 1:\n",
    "            allowed.append(ids[0])\n",
    "\n",
    "    def prefix_allowed_tokens_fn(batch_id, full_ids):\n",
    "        if len(full_ids[input_len:]) == 0 and allowed:\n",
    "            return allowed\n",
    "        return [tok.eos_token_id]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            prefix_allowed_tokens_fn=(prefix_allowed_tokens_fn if allowed else None),\n",
    "        )\n",
    "\n",
    "    txt = tok.decode(out_ids[0, input_len:], skip_special_tokens=True).strip()\n",
    "    digit = next((c for c in txt if c in \"123456\"), None)\n",
    "    return IDX2LABEL.get(digit, \"Other\")\n",
    "\n",
    "print(classify_digits(\"windshield cracked and needs repair\", pipe))               # → CarWindshield\n",
    "print(classify_digits(\"premium up 20% at renewal, add named driver?\", pipe))     # → CarRenewal\n",
    "print(classify_digits(\"my car crashed into another car?\", pipe))                  # → CarCrash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other\n"
     ]
    }
   ],
   "source": [
    "print(classify_digits(\"windshield cracked and needs repair\", pipe)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
